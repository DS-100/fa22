{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480012c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw08.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1148b07c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# Homework 8: Snow (continued) + IMDb\n",
    "## `xarray` + SQL\n",
    "## Due Date: Thursday, November 10, 11:59 PM PDT\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7a329c",
   "metadata": {},
   "source": [
    "**Collaborators**: *list collaborators here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2db62a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This homework has two disjoint parts:\n",
    "\n",
    "**Part 1:** We will continue our explorations of worldwide snow cover from Lab 9 using the `xarray` package, uncovering interesting trends in snow density over time. [Click here to jump to Part 1](#part-1)\n",
    "\n",
    "**Part 2:** We will use SQL to dive deep into the Internet Movie Database (IMDb) and answer different questions involving movies, actors, and movie ratings. [Click here to jump to Part 2](#part-2).\n",
    "\n",
    "## Grading \n",
    "\n",
    "Grading is broken down into autograded answers and free response. For autograded answers, the results of your code are compared to provided and/or hidden tests. For free response, readers will evaluate how well you answered the question and/or fulfilled the requirements of the question.\n",
    "\n",
    "<!--\n",
    "<details>\n",
    "    <summary>[Click to Expand] <b>Scoring Breakdown</b></summary>-->\n",
    "|Question|Points|\n",
    "|---|---|\n",
    "|Q1 | 1 |\n",
    "|Q2 | 1 |\n",
    "|Q3 | 3 |\n",
    "|Q4a | 2 |\n",
    "|Q4b | 2 |\n",
    "|Q5 | 3 |\n",
    "|Q6 | 3 |\n",
    "|Q7 | 4 |\n",
    "|Q8 | 4 |\n",
    "|Total | 23 |\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1071af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import sqlalchemy\n",
    "from pathlib import Path\n",
    "\n",
    "#Comment out this line after you have run it\n",
    "!pip install ipython-sql\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight') # Use plt.style.available to see more styles\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "np.set_printoptions(threshold=5) # avoid printing out big matrices\n",
    "%matplotlib inline\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a68dae1",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "---\n",
    "\n",
    "<a id='part-1'></a>\n",
    "# Part 1: ERA5 Snow Cover (continued)\n",
    "\n",
    "(Click [here](#top) to jump back to the top of this notebook.)\n",
    "\n",
    "In this part of the homework, we will be continuing to explore worldwide snow accumulation trends from the ERA5 dataset from Lab 9. More specifically, we wish to look at the yearly minimum and maximum snow accumulation levels, and see if there are any interesting trends. Like in the lab, you will be using `xarray` to accomplish this part's tasks. The `xarray` [documentation](https://docs.xarray.dev/en/stable/) will be very helpful for this part of the assignment.\n",
    "\n",
    "Before getting into the tasks, we will first overview what you did in Lab 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71d7f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "DATA_DIR = Path('./data')\n",
    "monthly_2deg_path = DATA_DIR / \"era5_snow_monthly_2deg_aws_v20210920.nc\"\n",
    "ds = xr.open_dataset(monthly_2deg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6409d27c",
   "metadata": {},
   "source": [
    "First, let's look at the output of this `xarray.Dataset` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06c20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5a79b",
   "metadata": {},
   "source": [
    "Recall that an `xarray.Dataset` can be thought of as a generalization of a `pandas.DataFrame` that is especially suited for working with physical data. Physical datasets often consist of data collected at points at particular locations on Earth at particular times. We can think of this data as being indexed by three-dimensions: longitude, latitude, and time. Pandas DataFrames only have one-dimensional indexing (observations are only indexed by row numbers), making this data structure a bit cumbersome to work with in such applied contexts. An `xarray.Dataset` consists of `xarray.DataArray` objects, one for each measurement variable of interest (in the above `xarray.Dataset` object, there is only one measurement variable). An `xarray.DataArray` object contains such measurements indexed at locations in time and space. Thus, given an `xarray.DataArray` object containing snow density measurements, for instance, users can analyze snow density measurements at particular locations on Earth at particular times by providing inputting locations and times as opposed to querying rows of a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e01e01",
   "metadata": {},
   "source": [
    "In our variable `ds`, we have an `xarray.Dataset` object with one `xarray.DataArray` object, consisting of `snow_density` measurements across time and location. The following cell extracts the `xarray.DataArray` object consisting of snow density measurements, similar to extracting a column from a `Pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = ds.snow_density\n",
    "snow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce5b91",
   "metadata": {},
   "source": [
    "Recall `xarray` is also nice in that, if we wanted to average our snow density measurements across all time and plot the aggregate values by spatial location, we can do this in two lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "mean_map = ds.mean(\"time\")  # takes the mean across all variables in ds\n",
    "mean_map.snow_density.plot(); # extract snow_density DataArray, then plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff1a85",
   "metadata": {},
   "source": [
    "In **Question 4** of Lab 9, you were asked to make two figures showing the spatial distribution of snow density measurements for both February 1980 (Northern Hemisphere winter) and August 1980 (Southern Hemisphere summer). This could be done using the code in the following two cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613848a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow.sel(time='1980-02').plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec938b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow.sel(time='1980-08').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256929b",
   "metadata": {},
   "source": [
    "Notice how these plots make a lot of sense: snow cover is higher in the Northern hemisphere during winter time, and when summer comes around, that snow melts. However, at the same time, winter arrives in the Southern hemisphere, and so snow appears on mountains in South America and New Zealand.\n",
    "\n",
    "This is where Lab 9 left off. Now, let's continue analyzing the data, with the ultimate goal of understanding and displaying trends of snow accumulation over the years using `xarray`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e2f29",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0327295",
   "metadata": {},
   "source": [
    "In both the northern and southern hemispheres, make lineplots showing the average snow density (averaged across all locations in the respective hemisphere) on the y-axis and the date/time on the x-axis. To make answering Question 3 easier, also create `xarray.DataArray` objects containing this spatially-aggregated data, one for each hemisphere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d2397",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d82412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_snow_north = ...\n",
    "t_snow_north.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c7f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_snow_south = ...\n",
    "t_snow_south.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3c767",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61192626",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "For each hemisphere, we observe clear cycles in average snow accumulation over time, which makes sense because of seasonal temperature changes. However, the plots above are a little bit busy. For this question, make a similar plot, *but only show average snow density measurements for the northern hemisphere in the year 1979*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93da1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7534ba7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Question 3 \n",
    "\n",
    "Now that we have a sense of seasonal and yearly change in snow accumulation in both hemispheres, let's work to use `xarray` to extract yearly maxima and minima and get a sense of how these levels are changing over time.\n",
    "\n",
    "For this question, you will need to fill in the `extract_peaks` function such that, if you plugged in an `xarray.DataArray` containing average snow density measurements for each hemisphere over time (like the ones you made in Question 1), you'd return a `pandas.DataFrame` that looks like the following:\n",
    "\n",
    "<img src=\"snow-peaks-north-df.png\" width=\"900px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f94d3",
   "metadata": {},
   "source": [
    "When filling out the `extract_peaks` function, think about what information we want your DataFrame to contain, what information your `xarray.DataArray` objects contain already, and how you might write code to get the desired output.\n",
    "\n",
    "Some hints:\n",
    "\n",
    "1. First, we want to extract the years from the data and iterate over them using `range`\n",
    "2. When iterating over the years, for each year, extract the maximum and minimum snow accumulation measurements, as well as the day of year and dates that those measurements occured on. Amplitude is computed by taking the difference between a year's max and min snow accumulation levels, and all of this information will be stored in an array called `vals`.\n",
    "3. `peaks` should be an array consisting of all of the information in `vals`, plus any other columns we ask for in the above printout that is not already in `vals`.\n",
    "4. The `DataArray.idxmin` and `DataArray.idxmax` methods may be useful.\n",
    "5. If you have a `DataArray` called `x` containing single value (day of year where min snowfall happened in a single year, for example), and you'd rather extract that value from as an int/string/date etc., use `x.values.item`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592b575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_peaks(snow_data):\n",
    "    ...\n",
    "    years = ...\n",
    "    peaks = []\n",
    "    for y in years:\n",
    "    ...\n",
    "        vals = ...\n",
    "    ...\n",
    "\n",
    "    snow_peaks = pd.DataFrame(peaks, \n",
    "                              columns = ['year', 'min_date', 'max_date',\n",
    "                                         'min_dayofyear', 'max_dayofyear',\n",
    "                                         'min_snow', 'max_snow', 'amplitude'])\n",
    "\n",
    "    return snow_peaks\n",
    "\n",
    "peaks_north = extract_peaks(t_snow_north)\n",
    "peaks_north.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad9a0a",
   "metadata": {},
   "source": [
    "With this DataFrame, we can now quickly explore several questions. For example, during what day of the year do the min and max happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "plt.plot('year', 'min_dayofyear', data=peaks_north);\n",
    "plt.plot('year', 'max_dayofyear', data=peaks_north);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258e87b",
   "metadata": {},
   "source": [
    "What is the min and max amount of snow at those times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "plt.plot('year', 'min_snow', data=peaks_north);\n",
    "plt.plot('year', 'max_snow', data=peaks_north);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4d475",
   "metadata": {},
   "source": [
    "Given the difference in scales, it's a bit easier to see what is happening if we plot the min and max separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "plt.plot('year', 'min_snow', data=peaks_north);\n",
    "plt.plot('year', 'min_snow', 'r.', data=peaks_north);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f45f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "plt.plot('year', 'max_snow', data=peaks_north);\n",
    "plt.plot('year', 'max_snow', 'r.', data=peaks_north);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed8da7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br/><br/>\n",
    "\n",
    "---\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "---\n",
    "\n",
    "<a id='part-1'></a>\n",
    "# Part 2: The IMDB (mini) Dataset\n",
    "\n",
    "\n",
    "(Click [here](#top) to jump back to the top of this notebook.)\n",
    "\n",
    "We will explore a miniature version of the [IMDb Dataset](https://www.imdb.com/interfaces/). This is the same dataset that we used for this week's lab. The remainder of this overview section is copied from this week's lab.\n",
    "\n",
    "Let's load in the database in two ways (using both Python and cell magic) so that we can flexibly explore the SQL database.\n",
    "\n",
    "A few reminders: \n",
    "* **Only SQL code written with `pd.read_sql` will be graded.**  You should feel free to create `%%sql` cells **after** your Python answer + autograder cells to reduce debugging headaches, but you will still need to copy over any SQL to the Python answer cells. **Do not** add new cells betwen the question and the grading cells; it will cause errors when we run the autograder, and it will sometimes cause an error in generating the PDF file.\n",
    "\n",
    "* **Caution: Be careful with large SQL queries!!** You may need to reboot your Jupyter Hub instance if it stops responding. **Use the LIMIT keyword** to avoid printing out 100k-sized tables (but remember to remove it).\n",
    "\n",
    "* Films and movies are equivalent ways of expressing the condition that `titleType = 'movie'`, and they are used interchangeably throughout the assignment. They refer to the same thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f535629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell and the next one\n",
    "engine = sqlalchemy.create_engine(\"sqlite:///data/imdbmini.db\")\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///data/imdbmini.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9904168",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61f382",
   "metadata": {},
   "source": [
    "Let's take a look at the table schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49311c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- just run this cell --\n",
    "SELECT * FROM sqlite_master WHERE type='table';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610afbd",
   "metadata": {},
   "source": [
    "From running the above cell, we see the database has 4 tables: `Name`, `Role`, `Rating`, and `Title`.\n",
    "\n",
    "<details>\n",
    "    <summary>[<b>Click to Expand</b>] See descriptions of each table's schema.</summary>\n",
    "    \n",
    "**`Name`** – Contains the following information for names of people.\n",
    "    \n",
    "- nconst (text) - alphanumeric unique identifier of the name/person\n",
    "- primaryName (text)– name by which the person is most often credited\n",
    "- birthYear (integer) – in YYYY format\n",
    "- deathYear (integer) – in YYYY format\n",
    "    \n",
    "    \n",
    "**`Role`** – Contains the principal cast/crew for titles.\n",
    "    \n",
    "- tconst (text) - alphanumeric unique identifier of the title\n",
    "- ordering (integer) – a number to uniquely identify rows for a given tconst\n",
    "- nconst (text) - alphanumeric unique identifier of the name/person\n",
    "- category (text) - the category of job that person was in\n",
    "- characters (text) - the name of the character played if applicable, else '\\\\N'\n",
    "    \n",
    "**`Rating`** – Contains the IMDb rating and votes information for titles.\n",
    "    \n",
    "- tconst (integer) - alphanumeric unique identifier of the title\n",
    "- averageRating (text) – weighted average of all the individual user ratings\n",
    "- numVotes (text) - number of votes (i.e., ratings) the title has received\n",
    "    \n",
    "**`Title`** - Contains the following information for titles.\n",
    "    \n",
    "- tconst (text) - alphanumeric unique identifier of the title\n",
    "- titleType (text) -  the type/format of the title\n",
    "- primaryTitle (text) -  the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "- isAdult (text) - 0: non-adult title; 1: adult title\n",
    "- startYear (text) – represents the release year of a title.\n",
    "- runtimeMinutes (integer)  – primary runtime of the title, in minutes\n",
    "    \n",
    "</details>\n",
    "\n",
    "<br/><br/>\n",
    "From the above descriptions, we can conclude the following:\n",
    "* `Name.nconst` and `Title.tconst` are primary keys of the `Name` and `Title` tables, respectively.\n",
    "* `Role.nconst` and `Role.tconst` are **foreign keys** that point to `Name.nconst` and `Title.tconst`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7ff06",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 4\n",
    "\n",
    "### Question 4a\n",
    "How far back does our data go? Does it only include recent data, or do we have information about older movies and movie stars as well? \n",
    "\n",
    "List the **10 oldest `movie` titles** by `startYear` and then `primaryTitle` both in **ascending** order.  Do not include films where the `startYear` is `NULL`.  The output should contain the `startYear`, `primaryTitle`, and `titleType`.\n",
    "\n",
    "Remember, you can create a `%%sql` cell **after** the grader cell as scratch work. Just be sure to copy the query back into the Python cell to run the autograder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bebd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q4a = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q4a = pd.read_sql(query_q4a, engine)\n",
    "res_q4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7719ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b1391",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "### Question 4b\n",
    "\n",
    "Next, let's calculate the distribution of films by year. Write a query that returns the **total** `movie` titles for each `startYear` in the `Title` table as `total`.  Keep in mind that some entries may not have a `startYear` listed -- you should filter those out.  Order your final results by the `startYear` in **ascending** order.\n",
    "\n",
    "The first few records of the table should look like the following (but you should compute the entire table).\n",
    "\n",
    "\n",
    "| |startYear|total|\n",
    "|-----|------|-----|\n",
    "|**0**|1915|1|\n",
    "|**1**|1920|1|\n",
    "|**2**|1921|1|\n",
    "|**3**|1922|1|\n",
    "|...|...|...|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce14ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q4b = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q4b = pd.read_sql(query_q4b, engine)\n",
    "res_q4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23dedf3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14710c7d",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "The following should generate an interesting plot of the number of films that premiered each year. Notice there is a dip between the 1920s and late 1940s. Why might that be? *This question is rhetorical; you do not need to write your answer anywhere.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "px.bar(res_q4b, x=\"startYear\", y=\"total\",\n",
    "       title=\"Number of films premiered each year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8ac67",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 5\n",
    "\n",
    "Who are the **top 10 most prolific movie actors**?\n",
    "\n",
    "Define the term \"movie actor\" is defined as anyone with an `actor` or `actress` job category role in a `movie` title.\n",
    "\n",
    "Your SQL query should output exactly two fields named `name` (the movie actor name) and `total` (the number of movies the movie actor appears in). Order the records by `total` in descending order, and break ties by ordering by `name` in ascending order.\n",
    "\n",
    "Your result should look something like the following, but without `????`:\n",
    "\n",
    "| | name | total |\n",
    "|-----|-----|-----|\n",
    "|**0**| ???? | 64 |\n",
    "|**1**| ???? | 54 |\n",
    "|**2**| ???? | 53 |\n",
    "|**3**| ???? | 49 |\n",
    "|**4**| ???? | 46 |\n",
    "|**5**| ???? | 43 |\n",
    "|**6**| ???? | 41 |\n",
    "|**7**| ???? | 40 |\n",
    "|**8**| ???? | 40 |\n",
    "|**9**| ???? | 39 |\n",
    "\n",
    "Some hints: \n",
    "\n",
    "* ***The query should take < 2 minutes to run.***\n",
    "* Google the top of the list and see if it makes sense.\n",
    "* If you want to include a non-aggregate field in the `SELECT` clause, it must also be included in the `GROUP BY` clause.\n",
    "<!--* You can assume each movie actor only has one role per film. If you're not sure how this hint affects your query, ignore this hint.-->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eaba01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q5 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q5 = pd.read_sql(query_q5, engine)\n",
    "res_q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ea236",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d073e18",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 6: The `CASE` Keyword\n",
    "\n",
    "The `Rating` table has the `numVotes` and the `averageRating` for each title. Which `movie` titles were **\"big hits\"**, defined as a movie with over 100,000 votes? Construct the following table:\n",
    "\n",
    "| | isBigHit | total |\n",
    "|-----|-----|-----|\n",
    "|**0**| no | ???? |\n",
    "|**1**| yes | ???? |\n",
    "\n",
    "Where `????` is replaced with the correct values. The row with `no` should have the count for how many movies **are not** big hits, and the row with `yes` should have the count of how many movies **are** big hits.\n",
    "\n",
    "* Rating.numVotes currently consists of string objects, use `CAST(Rating.numVotes AS int)` to convert them to integer.\n",
    "* You will need to use  some type of `JOIN`.\n",
    "* You may also consider using a `CASE WHEN ... IS ... THEN 'yes' ... ELSE ... END` statement. `CASE` statements are the SQL-equivalent of Python `if... elif... else` statements. To read up on `CASE`, take a look at the following links:\n",
    "    - https://mode.com/sql-tutorial/sql-case/\n",
    "    - https://www.w3schools.com/sql/sql_ref_case.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d0c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q6 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q6 = pd.read_sql(query_q6, engine)\n",
    "res_q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099803ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daaa1b9",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 7\n",
    "\n",
    "**How does film length relate to ratings?**  To answer this question we want to bin `movie` titles by length and compute the average of the average ratings within each length bin. We will group movies by 10-minute increments -- that is, one bin for movies \\[0, 10) minutes long, another for \\[10, 20) minutes, another for \\[20, 30) minutes, and so on. Use the following code snippet to help construct 10-minute bins: \n",
    "\n",
    "```\n",
    "ROUND(runtimeMinutes / 10.0 + 0.5) * 10 AS runtimeBin\n",
    "```\n",
    "\n",
    "Construct a table containing the **`runtimeBin`**, the **average** of the **average ratings** (as `averageRating`), the **average number of votes** (as `averageNumVotes`), and the number of `titles` in that **runtimeBin** (as `total`).  Only include movies with **at least 10000 votes**.  Order the final results by the value of `runtimeBin`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187da77f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q7 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q7 = pd.read_sql(query_q7, engine)\n",
    "res_q7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09dbe1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef130185",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "If your SQL query is correct you should get some interesting plots below.  This might explain why directors keep going a particular direction with film lengths.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71efebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "px.bar(res_q7, x=\"runtimeBin\", y=\"total\",\n",
    "       title=\"Distribution of Movie Runtimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this cell\n",
    "px.line(res_q7, x=\"runtimeBin\", y=\"averageRating\",\n",
    "        title=\"Movie Ratings vs. Runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(res_q7, x=\"runtimeBin\", y=\"averageNumVotes\",\n",
    "        title=\"Movie Number of Votes vs. Runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad885a80",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "## Question 8\n",
    "\n",
    "\n",
    "Which **movie actors** have the highest average ratings across all the **movies** in which they star? Again, define \"movie actor\" as anyone with an `actor` or `actress` job category role in a `movie` title.\n",
    "\n",
    "Construct a table consisting of the **movie actor's name**  (as `name`) and their **average actor rating** (as `actorRating`) computed by rescaling ratings for movies in which they had a role:\n",
    "\n",
    "$$\n",
    "\\text{actorRating} = \n",
    "\\frac{\\sum_m \\text{averageRating}[m] * \\text{numVotes}[m]}{\\sum_m \\text{numVotes}[m]}\n",
    "$$\n",
    "\n",
    "Some notes:\n",
    "* Note that if an actor/actress has multiple `role` listings for a film then that film will have a bigger impact in the overall average (this is desired).\n",
    "* ***The query should take < 3 minutes to run.***\n",
    "* Only consider ratings where there are **at least 1000** votes and only consider movie actors that have **at least 20 rated performances**. Present the movie actors with the **top 10** `actorRating` in descending order and break ties alphabetically using the movie actor's name.\n",
    "\n",
    "The results should look something like this but without the `????`, and with higher rating precision.\n",
    "\n",
    "| | name | actorRating |\n",
    "|-----|-----|-----|\n",
    "|**0**|????|8.4413...|\n",
    "|**1**|????|8.2473...|\n",
    "|**2**|????|8.1383...|\n",
    "|**3**|????|8.1339...|\n",
    "|**4**|????|8.0349...|\n",
    "|**5**|????|7.9898...|\n",
    "|**6**|????|7.9464...|\n",
    "|**7**|????|7.9330...|\n",
    "|**8**|????|7.9261...|\n",
    "|**9**|????|7.8668...|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f276b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_q8 = \"\"\"\n",
    "...       # replace this with\n",
    "...;      # your multi-line solution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "res_q8 = pd.read_sql(query_q8, engine)\n",
    "res_q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005f749",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77916a3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": []
   },
   "source": [
    "## Congratulations!\n",
    "\n",
    "Congrats! You are finished with this homework assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867d8ea",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ff152",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9afbff",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q4a": {
     "name": "q4a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q4a.shape == (10, 3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q4a.columns) == set(['startYear', 'primaryTitle', 'titleType'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q4b.shape == (102, 2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q5.shape == (10, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q5.columns) == set(['name', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q6.shape == (2, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q6.columns) == set(['isBigHit', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q6['isBigHit']) == set(['yes', 'no'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q7.shape == (26, 4)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q7.columns) == set(['runtimeBin', 'averageRating', 'averageNumVotes', 'total'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res_q7[\"runtimeBin\"].min() == 50.0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res_q7[\"runtimeBin\"].max() == 370.0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_q8.shape == (10, 2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(res_q8.columns) == set(['name', 'actorRating'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
