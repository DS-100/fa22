{
  "0": {
    "id": "0",
    "title": "Staff Pictures",
    "content": "Staff Pictures Staff pictures go here",
    "url": "http://localhost:4000/sp22/resources/assets/staff_pics/README/",
    "relUrl": "/resources/assets/staff_pics/README/"
  },
  "1": {
    "id": "1",
    "title": "Announcements",
    "content": "Announcements Announcements are stored in the _announcements directory and rendered according to the layout file, _layouts/announcement.html. Week 0 Announcements Welcome to Data 100! We’re still getting this site set up. Some information here may be inaccurate. We will remove this warning once the site is complete. Announcements We will not be updating this page with announcements. For the latest announcements, make sure to check our Piazza.",
    "url": "http://localhost:4000/sp22/announcements/",
    "relUrl": "/announcements/"
  },
  "2": {
    "id": "2",
    "title": "Calendar",
    "content": "Calendar Office Hours Queue Zoom (Online OH only) Office Hours Calendar Lecture, Discussion, Lab, and Special Events Calendar Office Hours Calendar In-person office hours are in blue, while virtual office hours are in brown. Lab help sections are in green. Click on each event to see which GSI and/or tutor is running each office hour time. You should come to these with questions about anything – labs, homeworks, discussions, concepts, etc. To access in-person office hours, go to the room in the location of the office hour slot you’re planning on attending. To access virtual office hours, go to our Office Hours Zoom and join the breakout room of the question you are working on. Instructor office hours with Josh and Lisa appear in red. You should come to these with questions about concepts. To access instructor office hours, use the Zoom links posted on Ed. If you would like to meet with the instructors and none of these times work for you, please reach out to us privately. Lecture, Discussion, Lab, and Special Events Calendar This calendar contains times for live lectures (in brown) live discussion sections (in orange) live lab help sections (in green)",
    "url": "http://localhost:4000/sp22/calendar/",
    "relUrl": "/calendar/"
  },
  "3": {
    "id": "3",
    "title": "Graduate Project",
    "content": "Graduate Project Table of Contents Introduction Timeline Deliverables and Grade Breakdown Datasets Introduction The graduate project is offered only to students enrolled in Data C200 or CS C200A. Other students are welcome to explore the questions and datasets in the project for learning, but their work will not be graded or counted towards their final grades. The purpose of the project is to give students experience in both open-ended data science analysis and research in general. In this project, you will work with one or any combination of the following datasets provided to you to explore research questions that you define. Note: in addition to the general guideline, each option has its own set of additional requirements for Report Format and Submission. Be sure to consult the correct section for your project option. You will receive feedback from peer grading before the final deadline, and you are expected to incorporate the feedback into the final report and presentation. You will be graded on both the final report and presentation, as well as certain deliverables before the submission of the final reports, including your peer reviews. Teamwork: You can work alone or in a group with at most two other students. If you are interested in working with others, we will have an Ed post for teammate search. Everyone in the same group will receive the same grade. The group size will be taken into consideration for grading. Timeline Date (by EOD at 11:59pm) Event / Deliverable 4/2 Full grad project and datasets are released 4/9 Research proposal and project groups due 4/22 Project checkpoint 4/27 First draft of final report due 4/28 Peer grading starts 5/2 Peer grading due 5/9 Revised final report due 5/11 Presentation video due 5/13 Presentation video released (at discretion) Deliverables and Grade Breakdown Deliverable Weight Research proposal and project groups 10% Submission of first draft 10% Peer grading 15% Final report: analysis notebook 20% Final report: project writeup 30% Final presentation video 15% Datasets This section will contain the datasets we will provide to you to explore your research questions. Please note that: You must incorporate at least one of the provided datasets. You are welcome to bring in additional datasets to complement the datasets provided here, but you must cite the sources and clearly describe the content of any additional data you use in the final report. The datasets will be released when the full project is released in April.",
    "url": "http://localhost:4000/sp22/grad_proj/gradproject/",
    "relUrl": "/grad_proj/gradproject/"
  },
  "4": {
    "id": "4",
    "title": "Graduate Project",
    "content": "",
    "url": "http://localhost:4000/sp22/gradproject/",
    "relUrl": "/gradproject/"
  },
  "5": {
    "id": "5",
    "title": "Graduate Project",
    "content": "Graduate Project Table of Contents Introduction Timeline Deliverables and Grade Breakdown Datasets Accessing Datasets Topic 1: COVID-19 Topic 2: Climate and the Environment Topic 3: Emerging Researches and Technologies Report Format and Submission Rubrics Peer Grading Rubric Final Report: Analysis Notebook Grading Rubric Final Report: Project Writeup Grading Rubric Introduction The graduate project is offered only to students enrolled in Data C200 or CS C200A. Other students are welcome to explore the questions and datasets in the project for learning, but their work will not be graded or counted towards their final grades. The purpose of the project is to give students experience in both open-ended data science analysis and research in general. In this project, you will work with one or any combination of the following datasets provided to you to explore research questions that you define. Note: in addition to the general guideline, each option has its own set of additional requirements for Report Format and Submission. Be sure to consult the correct section for your project option. You will receive feedback from peer grading before the final deadline, and you are expected to incorporate the feedback into the final report and presentation. You will be graded on both the final report and presentation, as well as deliverables before the submission of the final reports, including your peer reviews. Teamwork: You can work alone or in a group with at most two other students. If you are interested in working with others, we will have an Ed post for teammate search. Everyone in the same group will receive the same grade. The group size will be taken into consideration for grading. Timeline Date (by EOD at 11:59pm) Event / Deliverable 4/9 Research proposal and project groups due 4/22 Project checkpoint 4/27 First draft of final report due 4/28 Peer grading starts 5/2 Peer grading due 5/9 Revised final report due 5/11 Presentation video due 5/13 Presentation video released (at discretion) Deliverables and Grade Breakdown Deliverable Weight Research proposal and project groups 10% Submission of first draft 10% Peer grading 15% Final report: analysis notebook 20% Final report: project writeup 30% Final presentation video 15% Datasets This section contains the datasets we will provide to you to explore your research questions. Please note that: You must incorporate at least one of the provided datasets. You are welcome to bring in additional datasets to complement the datasets provided here, but you must cite the sources and clearly describe the content of any additional data you use in the final report. Please be sure to consult the references on causal inference for guidance on how to work with multiple datasets if you decide on doing that. Accessing Datasets All the datasets provided by us can be found inside the shared directory on Datahub. graduate project datasets link on DataHub. If you wish to work on the project locally, you can also download the zip files containing the datasets for each topic. The following subsections contain the descriptions and additional requirements for each dataset. Topic 1: COVID-19 Dataset A: Testing and Mortality Statistics This dataset contains US reports on COVID-19 testing and cases from the COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University and CDC (Centers for Disease Control and Prevention). You can access all the data here within the Dataset A directory on DataHub: csse_covid_19_daily_reports_us.csv contains US daily reports (documentation) cdc_death_counts_by_sex_age_state.csv contains US weekly reports on deaths involving COVID-19, pneumonia, and influenza reported to NCHS by sex, age, group, and state. (documentation) cdc_death_counts_by_conditons.csv contains US weekly reports on health conditions and contributing causes mentioned in conjunction with deaths involving COVID-19. (documentation) You must choose to work with at least 2 of the reports above in your analysis. Dataset B: Impact on Health Care This dataset contains reports from the Household Pulse Survey launched by NCHS in partnership with the U.S. Census Bureau; it focuses on how COVID-19 has affected survey correspondents’ mental health and their access to health care. In addition, it provides statistics on usage of telemedicine by healthcare providers. You can access all the data here within the Dataset B directory on DataHub: nchs_covid_indicators_of_anxiety_depression.csv contains survey estimates of responses to questions that are indicators of anxiety or depression based on reported frequency of symptoms within the past week. (documentation) nchs_covid_mental_health_care.csv contains survey estimates of responses to questions that ask if participants have accessed mental health care in the past 4 weeks. (documentation) nchs_covid_health_insurance_coverage.csv contains survey estimates of responses to questions that ask about participants’ health insurance coverage. (documentation) nchs_covid_reduced_access_to_health_care.csv contains survey estimates of responses to questions that ask if participants have experienced delay or been refused health care due to COVID-19. (documentation) nchs_covid_telemedicine_usage.csv contains survey estimates of responses to questions that ask if healthcare providers offered telemedicine (including video and telephone appointments) – both during and before the pandemic – and about the use of telemedicine during the pandemic. (documentation) You must choose to work with at least 3 of the reports above in your analysis. Dataset C: Ongoing Researches This dataset contains (in full-text and metadata form) scholarly articles related to COVID-19. The data are optimized for machine readability and made available for use by the global research community. The dataset is intended to mobilize researchers to generate new insights from the articles in support of the fight against this infectious disease. You can access the link to obtain the data here within the Dataset C directory on DataHub: covid_open_research_dataset.txt contains the link that will guide you to obtain the full-text and metadata dataset of COVID-related research articles. (documentation) Topic 2: Climate and the Environment Dataset A: General Measurements and Statistics This dataset contains some general statistics and measurements of various aspects of the climate and the environment. You can access all the data here within the Dataset A directory on DataHub. It includes the following reports: daily_global_weather_2020.csv contains data on daily temperature and precipitation measurements. To learn how to use the data from this file, please read the following section on the first report. us_greenhouse_gas_emissions_direct_emitter_facilities.csv and us_greenhouse_gas_emission_direct_emitter_gas_type.csv contain data reported by EPA (Environment Protection Agency) on greenhouse gas emissions, detailing the specific types of gas reported by facilities and general information about the facilities themselves. The dataset is made available through EPA’s GHGRP (Greenhouse Gas Reporting Program). us_air_quality_measures.csv contains data from the EPA’s AQS (Air Quality System) that measures air quality on a county level from approximately 4000 monitoring stations around the country. (source) The following subsection contains more details on how to work with the first report on global daily temperature and precipitation: The first report on daily temperature and precipitation is measured by weather stations in the Global Historical Climatology Network for January to October 2020. The data in daily_global_weather_2020.csv is derived from the source file at https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2020.csv.gz. To help you get started with a dataset of manageable size, we have preprocessed the GHCN dataset to include only the average temperature and precipitation measurements from stations that have both measurements. Each row in the preprocessed dataset contains both the average temperature and precipitation measurements for a given station on a given date. If you wish to explore the climate data for a different year, you can use the GHCN_data_preprocessing.ipynb notebook to download and perform the preprocessing described above. Please be advised that depending on the dataset size for a given year, GHCN_data_preprocessing.ipynb may not run on DataHub. We will not be providing infrastructural support for running the notebook, but you are welcome to run it on a different machine you have access to or ask a GSI to dump the data for you. The data contains only the (latitude, longitude) coordinates for the weather stations. To map the coordinates to geographical locations, the reverse-geocoder package mentioned in the References section might be helpful. Dataset B: Biodiversity in the Ecosystem This dataset contains studies focused specifically on the impact of environmental and climate changes on biodiversity and the local ecosystems. You can access all the data here within the Dataset B directory on DataHub. It includes the following reports: bioCON_plant_diversity.csv contains data collected as part of an ecological experiment, BioCON (Biodiversity, CO2, and Nitrogen), that started in 1997 and focused on studying biodiversity within the plant species at Cedar Creek Ecosystem Science Preserve. (documentation) plant_pollinator_diversity_set1.csv and plant_pollinator_diversity_set2.csv contain ecological data collected from a long-term observation study from 2011 to 2018 that focuses on plant-pollinator interaction and its impact on local biodiversity. (documentation) national_parks_biodiversity_parks.csv and national_parks_biodiversity_species.csv contain data published by the National Park Service on animal and plant species identified in individual national parks. Topic 3: Emerging Researches and Technologies Dataset A: Space Exploration This dataset contains a set of reports from pioneering researches that explore the outer space. Much of the data from these studies have provided a rich foundation for a variety of large-scale research projects that explore widely discussed topics such as habitable exoplanets or search for extraterrestrial life. You can access all the data here within the Dataset A directory on DataHub. It includes the following reports: kepler_exoplanet_search.csv contains data collected by NASA from the Kepler Space Observatory as part of a long-term study on finding habitable exoplanets from over 10,000 candidates. (source) kelper_planetary_system_composite.csv contains data collected by NASA from the Kelper Space Observatory as part of an ongoing study that tabulates all confirmed planetary systems outside the solar system. You are encouraged to use the composite data in conjunction with the exoplanet search results above. (source) nasa_neows.csv contains data collected from NASA’s NeoWs (Near Earth Object Web Service) that collects information on near earth asteroids. Dataset B: Recommender Systems A recommender system is an information filtering system that focuses on predicting the preference a user would give to an item by predicting its rank; it is used in a variety of areas, such as search engines, online shopping platforms, etc. This dataset contains a set of reports on various tools using a recommender system. You can access the links to obtain all the data here within the Dataset B directory on DataHub. It includes the following reports: fitness_recommendation.txt contains a link to access the fitness data from sequential sensors for various workouts. (documentation) amazon_reviews.txt contains a link to access the data on a subset of Amazon product reviews. The report includes metadata such as ratings and text on the reviews and general information about the product. (documentation) Report Format and Submission The project submission should include the following two components. [Component 1]. Analysis Notebooks. The Jupyter Notebook(s) containing all the analyses that you performed on the datasets to support your claims in the narrative notebook. Make sure that all references to datasets are done as data/[path to data files]. You can copy the datasets from ~/shared/grad_proj/multiple_datasets into data/ at the top-level directory for your project on DataHub to do this. Your analysis notebook(s) should address all of the following components in the data science lifecycle. Please note that a thorough explanation of your thought process and approach is as important as your work. We have provided a few preliminary questions/tips you can think about for each part: Data Sampling and Collection How were the data collected? Was there any potential bias introduced in the sampling process? Data Cleaning What type of data are you currently exploring? What is the granularity of the data? What does the distribution of the data look like? Are there any outliers? Are there any missing or invalid entries? Exploratory Data Analysis Is there any correlation between the variables you are interested in exploring? How would you cleanly and accurately visualize the relationship among variables? Data Modeling and Inferences Please note that the following datasets have a data modeling requirement, i.e. you need to utilize at least 1 machine learning model we teach in this class in your project: Topic 1 - Dataset A, Topic 1 - Dataset C, Topic 2 - Dataset A, Topic 3 - Dataset A, Topic 3 - Dataset B. For datasets not mentioned above, you are welcome to continue building machine learning model(s). Otherwise, we will be placing more emphasis on the inference part instead. Here are a few components your notebook must address if your focus is on modeling: What type of machine learning problem are you investigating? What model do you plan on using and why? Does your model require hyperparameter tuning? If so, how do you approach it? How do you engineer the features for your model? What are the rationales behind selecting these features? How do you perform cross validation on your model? What loss metrics are you using to evaluate your model? From a bias-variance tradeoff standpoint, how do you assess the performance of your model? How do you check if it is overfitting? How would you improve your model based on the outcome? If you are choosing to pursue your research question from an inference angle Your notebook must demonstrate sufficient analysis and visualization to support your conclusion. You must have a clearly constructed hypothesis test (including a clearly defined test statistic, significance level, and justification of chosen procedure) We will not restrict you to the type of statistical test you conduct as there are many different statistical techniques that may apply to your case. However, we also ask that you provide detailed justification for the techniques you choose and how it allows you make those inferences. [Component 2]. Project Writeup. This is a single PDF that summarizes your workflow and what you have learned. It should be structured as a research paper and include a title, list of authors, abstract, introduction, description of data, description of methods, summary of results, and discussion. Make sure to number figures and tables and include informative captions. If you wish, you can render the PDF using LaTeX, provided that the provenance of the figures is clearly labeled in the main narrative, and the figures can be reproduced by running the analysis notebooks Specifically, you should address the following in the narrative: Clearly stated research questions and why they are interesting and important. You must include at least one research question involving at least one or more datasets from one of the topics we provided, but you may include additional research questions about each individual dataset. At least one of your research questions has to include a modeling component, e.g., can we build a model using climate data to predict growth in COVID-19 cases accurately? A brief survey of related work on the topic(s) of your analysis and how your project differs from or complements existing research. If applicable, descriptions of additional datasets that you gathered to support your analysis. Methodology: carefully describe the methods you use and why they are appropriate for answering your search questions. It must include a brief overview of causal inference, which should be written in a way such that another student in Data 100 who has never been exposed to the concept can carry out the analyses involving the datasets in your project. a detailed description of how modeling is done in your project, including inference or prediction methods used, feature engineering and regularization if applicable, and cross-validation or test data as appropriate for model selection and evaluation. Interesting findings* about each dataset when analyzed individually. Include visualizations and descriptions of data cleaning and data transformation necessary to perform the analysis that led to your findings. Interesting findings* involving your datasets. Include visualizations and descriptions of data cleaning and data transformation necessary to perform the analysis that led to your findings. Analysis of your findings to answer your research question(s). Include visualizations and specific results. If your research questions contain a modeling component, you must compare the results using different inference or prediction methods (e.g., linear regression, logistic regression, or classification and regression trees). Can you explain why some methods performed better than others? An evaluation of your approach and discuss any limitations of the methods you used. Describe any surprising discoveries that you made and future work. * Examples of interesting findings: interesting data distributions and trends, correlations between different features, the relationship between the data distribution for the general population and specific datasets (e.g., the gender distribution in the census dataset vs. in the mental health dataset), specific features that are notably effective/ineffective for prediction. The narrative notebook should include figures sparingly to support specific claims. It can include runnable components, but it should not have large amounts of code. The length of the report should be 8+/-2 pages when it is printed as a PDF, excluding figures and code. Tip: if you need to write a large amount of $ LaTeX$, you may want to use the %%latex cell magic. Please submit everything as a zip file to the final report submission link. Please make sure the folder in the zip file has the following structure: studentIDs/ data/[all datasets used] analysis/[analysis notebooks] narrative/[narrative notebook] figures/[figures included in the narrative notebook] For groups with multiple members, please use student IDs joined by _ as the name for the top-level directory. The analysis notebooks must be runnable within this directory structure. If the narrative notebook includes any figures that are created in the analysis notebooks, the figures should be saved to figures/ by the analysis notebooks and imported from figures/ by the narrative notebook. Rubrics Peer Grading Rubric Each group will peer grade the projects from another group. The review will be graded out of a total of 15 points. Each review should include the following components: A summary of the report (5 points). The summary should address at least the following: What research question does the group propose? Why is it important? How does the dataset relate to the research question? What data modeling/inference techniques do the group primarily use to gain insights into their research question? Why are these techniques suitable for the task? What are the next steps a researcher can take if they want to investigate the question further based off the work in the project? An evaluation of the report based on the Data Science Lifecycle (10 points, 2 points per component). The review should include at least one strong point and one suggestion for improvement for each of the following components in the project: Data collection and sampling Data cleaning Exploratory data analysis (including data wrangling and visualization) Data modeling (including feature engineering, selection of the model, and evaluation of the model’s performance) Inference (do the results from the model sufficiently support the conclusion within the report?) Final Report: Analysis Notebook Grading Rubric The analysis notebook will be graded out of a total of 20 points based on the following set of criteria: Criterion Point Code readability and documentation 5 Proper and sufficient utilization of Python libraries 5 Overall code quality 3 Replicability of the results 7 Final Report: Project Writeup Grading Rubric The project writeup will be graded out of a total of 30 points based on the following set of criteria: Criterion Point Introduction, motivation, and presentation of the research question(s) 3 Exploratory data analysis 5 Modeling and inference techniques 7 Analysis of results 7 Implementation of peer review feedback 3 Discussion of potential societal impacts and/or ethical concerns 2 Overall clarity and structure of the report 3 Causal Inference When studying the relationship between datasets, you might want to consult the following references on causality vs. correlation. Oftentimes, it is tempting to make claims about causal relationships when there is not enough evidence from the data to support such claims. Please review the following references, or other reputable references that you find on the topic to familiarize yourself with relevant concepts and methods. Data 102 Data, Inference, and Decisions Spring 2020: Lecture 13: Causal Inference I. Moritz Hardt. Hernán MA, Robins JM (2020). Causal Inference: What If. Boca Raton: Chapman &amp; Hall/CRC. Advanced Data Analysis from an Elementary Point of View by Cosma Rohilla Shalizi",
    "url": "http://localhost:4000/sp22/grad_proj/gradproject_full/",
    "relUrl": "/grad_proj/gradproject_full/"
  },
  "6": {
    "id": "6",
    "title": "Home / Schedule",
    "content": "Principles and Techniques of Data Science UC Berkeley, Spring 2022 Lecture Zoom Discussion Sign-Up/Zoom Office Hour/Lab Help Josh Hug he/him/his hug@cs.berkeley.edu Lisa Yan she/her yanlisa@eecs.berkeley.edu Jump to current week: here. Lecture is hybrid: in-person in Li Ka Shing 245 and online via Zoom (see link above). Recordings will be posted within 12 hours of live lecture. Frequently Asked Questions: Before posting on the class Ed, please read the class FAQ page. Join Ed: here. Textbook readings are optional and actively in development. See the Resources for more details. Note: The schedule of lectures and assignments is subject to change. Schedule Week 1 Jan 18 Lecture 1 Course Overview Ch. 1 Weekly Check 1 Weekly Check 1 (due Jan 24) Jan 20 Lecture 2 Sampling and Probability Ch. 2, 3.1 Jan 21 Discussion 1 Intro (solutions) (recording) Lab 1 Prerequisite Coding (due Jan 25) Homework 1 Intro + Prerequisites (due Jan 27) Week 2 Jan 24 Weekly Check 2 Weekly Check 2 (due Jan 31) Jan 25 Lecture 3 Pandas I Ch. 6.1, 6.5 Textbook: Pandas Reference Table Reference: Pandas API Documentation Jan 27 Lecture 4 Pandas II Ch. 6.2-6.4 Jan 28 Discussion 2 Sampling and Probability, Pandas (code) (solutions) (recording) Lab 2 Pandas (due Feb 1) Homework 2 Food Safety (due Feb 3) Week 3 Jan 31 Weekly Check 3 Weekly Check 3 (due Feb 7) Feb 1 Lecture 5 Data Wrangling, EDA Ch. 8-9 Feb 3 Lecture 6 Regex Ch. 12 Feb 4 Discussion 3 Pandas, Data Cleaning (code) (solutions) (recording) Lab 3 Data Cleaning (due Feb 8) Homework 3 Tweets (due Feb 10) Week 4 Feb 7 Weekly Check 4 Weekly Check 4 (due Feb 14) Feb 8 Lecture 7 Visualization I Ch. 10.1-10.3 Textbook: Seaborn Reference Table Textbook: Matplotlib Reference Table Feb 10 Lecture 8 Visualization II Feb 11 Discussion 4 Regex, Visualization (solutions) (recording) Lab 4 Transformations and KDE (due Feb 15) Homework 4 Bike Sharing (due Feb 17) Week 5 Feb 14 Weekly Check 5 Weekly Check 5 (due Feb 21) Feb 15 Lecture 9 Intro to Modeling, Simple Linear Regression Ch. 4 Feb 17 Lecture 10 Constant Model, Loss, and Transformations Ch. 14 Feb 18 Discussion 5 Modeling and Simple Linear Regression Lab 5 Modeling, Summary Statistics, Loss Functions (due Feb 22) Homework 5 Regression (on paper) (due Mar 3) Week 6 Feb 21 Weekly Check 6 Weekly Check 6 (due Feb 28) Feb 22 Lecture 11 Ordinary Least Squares (Multiple Linear Regression) Ch. 18.1 Feb 24 Midterm Midterm 1 (7-9 pm) Feb 25 Discussion 6 Ordinary Least Squares Lab 6 Simple Linear Regression (due Mar 1) Week 7 Feb 28 Weekly Check 7 Weekly Check 7 (due Mar 7) Mar 1 Lecture 12 Gradient Descent, sklearn Ch. 16 Mar 3 Lecture 13 Case Study (HCE): Fairness in Housing Appraisal Mar 4 Discussion 7 Gradient Descent Lab 7 Ordinary Least Squares, Feature Engineering (due Mar 8) Proj 1A Housing I (due Mar 10) Week 8 Mar 7 Weekly Check 8 Weekly Check 8 (due Mar 14) Mar 8 Lecture 14 Feature Engineering Ch. 21 Mar 10 Lecture 15 Regularization and Cross-Validation Ch. 21, 20.3 Mar 11 Discussion 8 HCE, Feature Engineering Lab 8 Cross-Validation and Regularization (due Mar 15) Proj 1B Housing II (due Mar 17) Week 9 Mar 14 Weekly Check 9 Weekly Check 9 (due Mar 21) Mar 15 Lecture 16 Probability I: Random Variables Ch. 3.2-3.5, 15.1 Mar 17 Lecture 17 Probability II: Estimators, Bias, and Variance Ch. 15.2-15.3 Mar 18 Discussion 9 Cross-Validation + Probability I Lab 9 Probability and Modeling (due Mar 29) Homework 6 Probability and Estimators (due Mar 31) Spring Break Mar 22 Spring Break Mar 24 Spring Break Week 10 Mar 28 Weekly Check 10 Weekly Check 10 (due Apr 4) Mar 29 Lecture 18 SQL I Ch. 7.1-7.2, 7.5 Mar 31 Lecture 19 SQL II Ch. 7.3-7.4 Apr 1 Discussion 10 Probability II + SQL I Lab 10 SQL (due Apr 5) Homework 7 SQL and PCA (due Apr 14) Apr 2 Grad Project Grad Project Released Week 11 Apr 4 Weekly Check 11 Weekly Check 11 (due Apr 11) Apr 5 Lecture 20 PCA Ch. 25 Apr 7 Midterm Midterm 2 (7-8:30 pm) Apr 8 Discussion 11 SQL II + PCA Lab 11 PCA (due Apr 12) Week 12 Apr 11 Weekly Check 12 Weekly Check 12 (due Apr 18) Apr 12 Lecture 21 Classification and Logistic Regression Ch. 23.1-23.3 Apr 14 Lecture 22 Logistic Regression II Ch. 23.4-23.8 Apr 15 Discussion 12 Logistic Regression I Lab 12 Logistic Regression (due Apr 19) Proj 2A Spam &amp; Ham I (due Apr 21) Week 13 Apr 18 Weekly Check 13 Weekly Check 13 (due Apr 25) Apr 19 Lecture 23 TBD Apr 21 Lecture 24 Decision Trees Ch. 26 Apr 22 Discussion 13 Logistic Regression II Lab 13 Decision Trees &amp; Random Forests (due Apr 26) Proj 2B Spam &amp; Ham II (due Apr 28) Week 14 Apr 25 Weekly Check 14 Weekly Check 14 (due May 2) Apr 26 Lecture 25 Clustering Ch. 27 Apr 27 Grad Project First Draft for Grad Project Due Apr 28 Lecture 26 Inference for Modeling Ch. 18.2 Apr 29 Discussion 14 Clustering Week 15 May 3 RRR Week May 5 RRR Week Week 16 May 9 Grad Project Final Draft of Grad Project Due May 13 Final Final Exam (7-10 pm)",
    "url": "http://localhost:4000/sp22/",
    "relUrl": "/"
  },
  "7": {
    "id": "7",
    "title": "Quick Guide to LaTeX",
    "content": "Quick Guide to LaTeX",
    "url": "http://localhost:4000/sp22/resources/assets/other/latex_guide/",
    "relUrl": "/resources/assets/other/latex_guide/"
  },
  "8": {
    "id": "8",
    "title": "Lecture 1 – Course Overview",
    "content": "Lecture 1 – Course Overview Presented by Josh Hug and Lisa Yan Content by Fernando Pérez, Alvin Wan, Suraj Rampure, Allen Shen, Joseph Gonzalez, Andrew Bray, Josh Hug, and Sam Lau slides code (launch) code HTML recording",
    "url": "http://localhost:4000/sp22/lecture/lec01/",
    "relUrl": "/lecture/lec01/"
  },
  "9": {
    "id": "9",
    "title": "Lecture 2 – Sampling and Probability",
    "content": "Lecture 2 – Data Sampling and Probability Presented by Lisa Yan Content by Fernando Pérez, Suraj Rampure, Ani Adhikari, Joseph Gonzalez, and Lisa Yan slides recording [Extra, Summer 2021] Binomial coefficient: Part 1, Part 2",
    "url": "http://localhost:4000/sp22/lecture/lec02/",
    "relUrl": "/lecture/lec02/"
  },
  "10": {
    "id": "10",
    "title": "Lecture 3 – Pandas I",
    "content": "Lecture 3 – Pandas I Presented by Josh Hug Content by Josh Hug slides code (launch) code HTML recording",
    "url": "http://localhost:4000/sp22/lecture/lec03/",
    "relUrl": "/lecture/lec03/"
  },
  "11": {
    "id": "11",
    "title": "Lecture 4 – Pandas II",
    "content": "Lecture 4 - Pandas, Part 2 Presented by Josh Hug Content by Josh Hug, Fernando Pérez slides code (launch) code HTML recording",
    "url": "http://localhost:4000/sp22/lecture/lec04/",
    "relUrl": "/lecture/lec04/"
  },
  "12": {
    "id": "12",
    "title": "Lecture 5 – Data Wrangling, EDA",
    "content": "Lecture 5 - Data Wrangling, EDA Presented by Lisa Yan Content by Lisa Yan slides code (launch) code HTML recording",
    "url": "http://localhost:4000/sp22/lecture/lec05/",
    "relUrl": "/lecture/lec05/"
  },
  "13": {
    "id": "13",
    "title": "Lecture 6 – Regular Expressions",
    "content": "Lecture 6 - Regular Expressions Presented by Lisa Yan Content by Lisa Yan and Josh Hug slides code (launch) code HTML DS100 Regex Reference Sheet on the Resources page recording",
    "url": "http://localhost:4000/sp22/lecture/lec06/",
    "relUrl": "/lecture/lec06/"
  },
  "14": {
    "id": "14",
    "title": "Lecture 7 – Visualizations I",
    "content": "Lecture 7 - Visualizations Presented by Josh Hug Content by Josh Hug slides code (launch) code HTML recording",
    "url": "http://localhost:4000/sp22/lecture/lec07/",
    "relUrl": "/lecture/lec07/"
  },
  "15": {
    "id": "15",
    "title": "Lecture 8 – Visualizations II",
    "content": "Lecture 8 - Visualizations II Presented by Josh Hug Content by Josh Hug slides code (launch) code HTML recording",
    "url": "http://localhost:4000/sp22/lecture/lec08/",
    "relUrl": "/lecture/lec08/"
  },
  "16": {
    "id": "16",
    "title": "Lecture 9 – SQL II",
    "content": "Lecture 9 – Modeling and Simple Linear Regression By Lisa Yan slides code (launch) code HTML recording",
    "url": "http://localhost:4000/sp22/lecture/lec09/",
    "relUrl": "/lecture/lec09/"
  },
  "17": {
    "id": "17",
    "title": "Lecture 10 – Visualization I",
    "content": "Lecture 10 – Visualization I Presented by Fernando Pérez Content by Fernando Pérez, Suraj Rampure, Ani Adhikari, Sam Lau, Yifan Wu, Deborah Nolan slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 10.0 Formal definition of visualization. The purpose of visualization in the data science lifecycle. 10.1 Formal definition of visualization. The purpose of visualization in the data science lifecycle. 10.1 10.2 Different ways we can map from data to properties of a visualization. 10.2 10.3 Defining distributions, and determining whether or not given visualizations contain a distribution. 10.3 10.4 Bar plots as a means of displaying the distribution of a qualitative variable, as well as for plotting a quantitative variable across several different categories. 10.4 10.5 Rug plots. Histograms, where areas are proportions. Reviewing histogram calculations from Data 8. Density curves as smoothed versions of histograms. 10.5 10.6 Describing distributions of quantitative variables using terms such as modes, skew, tails, and outliers. 10.6 10.7 Using box plots and violin plots to visualize quantitative distributions. Using overlaid histograms and density curves, and side by side box plots and violin plots, to compare multiple quantitative distributions. 10.7 10.8 Using scatter plots, hex plots, and contour plots to visualize the relationship between pairs of quantitative variables. Summary of visualization thus far. 10.8",
    "url": "http://localhost:4000/sp22/lecture/lec10/",
    "relUrl": "/lecture/lec10/"
  },
  "18": {
    "id": "18",
    "title": "Lecture 11 – Visualization II",
    "content": "Lecture 11 – Visualization II Presented by Suraj Rampure Content by Suraj Rampure, Ani Adhikari, Deborah Nolan, Joseph Gonzalez slides video playlist code Extra reading on colormaps: matplotlib colormaps (BIDS) How the Rainbow Color Map Misleads When to use Sequential and Diverging Palettes Color Use Guidelines A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 10.1 Ensuring that the axes in our visualizations aren&#39;t misleading. 10.1 10.2 Designing visualizations that are well-suited for making comparisons. 10.2 10.3 How to use color to create effective visualizations. How to choose color schemes that are clear and accessible. 10.3 10.4 How to choose markings that the human eye can easily interpret. Issues to avoid, such as jiggling baselines and overplotting. 10.4 10.5 Discussing the supplemental text that publication-ready plots need. 10.5 10.6 When to use smoothing. How kernel density estimates are created. Looking at various kernels. Understanding the impact of the bandwidth hyperparameter. 10.6 10.7 Discussing why we prefer linear relationships. Understanding how to &quot;reverse-engineer&quot; a linearized relationship to determine the true relationship. Identifying which transformations to use in order to linearize a relationship. 10.7",
    "url": "http://localhost:4000/sp22/lecture/lec11/",
    "relUrl": "/lecture/lec11/"
  },
  "19": {
    "id": "19",
    "title": "Lecture 12 – Modeling",
    "content": "Lecture 12 – Modeling Presented by Fernando Perez and Suraj Rampure Content by Fernando Perez, Suraj Rampure, Ani Adhikari, Deborah Nolan, Joseph Gonzalez slides video playlist code code HTML A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 12.1 Motivating examples of models. 12.1 12.2 Defining the constant model. Formalizing the notion of a parameter. 12.2 12.3 Loss functions and their purpose. Squared loss and absolute loss. Minimizing average loss (i.e. empirical risk). 12.3 12.4 Minimizing mean squared error for the constant model using calculus, to show that the sample mean is the optimal model parameter in this case. 12.4 12.5 Performing the same optimization as in the last video, but by using a non-calculus algebraic manipulation. 12.5 12.6 Minimizing mean absolute error for the constant model using calculus, to show that the sample median is the optimal parameter in this case. Identifying that this solution isn&#39;t necessarily unique. 12.6 12.7 Comparing the loss surfaces of MSE and MAE for the constant model. Discussing the benefits and drawbacks of squared and absolute loss. Recapping the &quot;modeling process&quot;. 12.7",
    "url": "http://localhost:4000/sp22/lecture/lec12/",
    "relUrl": "/lecture/lec12/"
  },
  "20": {
    "id": "20",
    "title": "Lecture 13 – Simple Linear Regression",
    "content": "Lecture 13 – Simple Linear Regression Presented by Anthony D. Joseph and Suraj Rampure Content by Suraj Rampure and Ani Adhikari slides video playlist code code HTML A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check Video Quick Check 13.0 Introduction and recap of the modeling process. 13.0 13.1 The correlation coefficient and its properties. 13.1 13.2 Defining the simple linear regression model, our first model with two parameters and an input variable. Motivating linear regression with the graph of averages. 13.2 13.3 Using calculus to derive the optimal model parameters for the simple linear regression model, when we choose squared loss as our loss function. 13.3 13.4 Visualizing and interpreting loss surface of the SLR model. 13.4 13.5 Interpreting the slope of the simple linear model. 13.5 13.6 Defining key terminology in the regression context. Expanding the simple linear model to include any number of features. 13.6 13.7 RMSE as a metric of accuracy. Multiple R-squared as a metric of explained variation. Summary. 13.7",
    "url": "http://localhost:4000/sp22/lecture/lec13/",
    "relUrl": "/lecture/lec13/"
  },
  "21": {
    "id": "21",
    "title": "Lecture 14 – Ordinary Least Squares",
    "content": "Lecture 14 – Ordinary Least Squares Presented by Anthony D. Joseph and Suraj Rampure Content by Suraj Rampure, Ani Adhikari, Deb Nolan, Joseph Gonzalez slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 14.1 A quick recap of the modeling process, and a roadmap for lecture. 14.1 14.2 Defining the multiple linear regression model using linear algebra (dot products and matrix multiplication). Introducing the idea of a design matrix. 14.2 14.3 Defining the mean squared error of the multiple linear regression model as the (scaled) norm of the residual vector. 14.3 14.4 Using a geometric argument to determine the optimal model parameter. 14.4 14.5 Residual plots. Properties of residuals, with and without an intercept term in our model. 14.5 14.6 Discussing the conditions in which there isn&#39;t a unique solution for the optimal model parameter. A summary, and outline of what is to come. 14.6",
    "url": "http://localhost:4000/sp22/lecture/lec14/",
    "relUrl": "/lecture/lec14/"
  },
  "22": {
    "id": "22",
    "title": "Lecture 15 – Modeling in Context: Fairness in Housing Appraisal",
    "content": "Lecture 15 – Modeling in Context: Fairness in Housing Appraisal Presented by Ari Edmundson and Margarita Boenig-Liptsin slides video playlist Video Quick Check 15.1 CCAO Intro + Problem 15.1 15.2 The CCAO&#39;s Solution 15.2 15.3 Key Takeaways 15.3 15.4 Lessons for Data Science Practice. 15.4",
    "url": "http://localhost:4000/sp22/lecture/lec15/",
    "relUrl": "/lecture/lec15/"
  },
  "23": {
    "id": "23",
    "title": "Lecture 16 – Feature Engineering",
    "content": "Lecture 16 – Feature Engineering Presented by Alvin Wan Content by Alvin Wan, Andrew Bray, Suraj Rampure, Ani Adhikari slides demo slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Currently, this lecture has no quick checks. We will be adding some shortly. Video Quick Check 16.1Introduction. 16.1 16.2Numpy: Coding a Linear Model 16.2 16.3Sklearn: Coding a Linear Model 16.3 16.4Where a Linear Model Struggles 16.4 16.5Benefit #1: Enhancing your linear model 16.5 16.6Sklearn: Imputing Data 16.6 16.7Benefit #2: Applying Domain Knowledge 16.7 16.8Benefit #3: Non-numeric and Categorical Data 16.8 16.9Conclusion: Overfitting and Next Steps 16.9",
    "url": "http://localhost:4000/sp22/lecture/lec16/",
    "relUrl": "/lecture/lec16/"
  },
  "24": {
    "id": "24",
    "title": "Lecture 17 – Bias and Variance",
    "content": "Lecture 17 – Bias and Variance Presented by Fernando Perez and Ani Adhikari Content by Fernando Perez, Ani Adhikari, Suraj Rampure slides playlist Bias-Variance decomposition derivation Important: You may want to review Lecture 3 for a refresher on random variables. A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 17.1Variance of random variables. Walking through an alternate calculation of variance. Variance of a linear transformation. 17.1 17.2Deriving the variance of a sum. Understanding covariance, correlation, and independence. 17.2 17.3Variance of an i.i.d. sum. Variance of the Bernoulli and binomial distributions. 17.3 17.4Variability of the sample mean. Reviewing inferential concepts from Data 8, but with the framework of random variables. 17.4 17.5Introducing the data generating process and prediction error. Model risk. 17.5 17.6Looking at different sources of error in our model – observation variance, model variance, and bias – and discussing how to mitigate them. 17.6 17.7Decomposing model risk into the sum of observation variance, model variance, and the square of bias. 17.7",
    "url": "http://localhost:4000/sp22/lecture/lec17/",
    "relUrl": "/lecture/lec17/"
  },
  "25": {
    "id": "25",
    "title": "Lecture 18 – Cross-Validation and Regularization",
    "content": "Lecture 18 – Cross-Validation and Regularization Presented by Anthony D. Joseph, Joseph Gonzalez, Suraj Rampure, Paul Shao Content by Joseph Gonzalez, Suraj Rampure, Paul Shao slides video playlist code Important: Read this before proceeding with the lectures, as it details what materials you should focus on. (This is also largely recapped in Video 18.1.) Sections 18.1 through 18.4 discuss train-test splits and cross-validation. 18.1, in addition to giving an overview of the lecture, walks through why we need to split our data into train and test in the first place, and how cross-validation works. It primarily consists of slides. 18.2 and 18.3 walk through the process of creating a basic train-test split, and evaluating models that we’ve fit on our training data using our testing data. Code is in “Part 1”. 18.4 walks through the process of implementing cross-validation. In this video there references to a Pipeline object in scikit-learn. This is not in scope for us, so do not worry about its details. Code is in “Part 1”. Sections 18.5 and 18.6 discuss regularization. 18.5 discusses why we need to regularize, and how penalties on the norm of our parameter vector accomplish this goal. 18.6 explicitly lists the optimal model parameter when using the L2 penalty on our linear model (called “ridge regression”). There are also three supplementary videos accompanying this lecture. They don’t introduce any new material, but may still be helpful for your understanding. They are listed as supplementary and not required since the runtime of this lecture is already quite long. They do not have accompanying Quick Checks for this reason. 18.7 and 18.8 walk through implementing ridge and LASSO regression in a notebook. These videos are helpful in explaining how regularization and cross-validation are used in practice. These videos again use Pipeline, which is not in scope. Code is in “Part 2”. 18.9 is another supplementary video, created by Paul Shao (a TA for Data 100 in Spring 2020). It gives a great high-level overview of both the bias-variance tradeoff and regularization. A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 18.1 Lecture overview. Training error vs. testing error. Why we need to split our data into train and test. How cross-validation works, and why it is useful. 18.1 18.2 Using scikit-learn to construct a train-test split. 18.2 18.3 Building a linear model and determining its training and test error. 18.3 18.4 Implementing cross-validation, and using it to help select a model. 18.4 18.5 An overview of regularization. 18.5 18.6 Ridge regression and LASSO regression. 18.6 18.7 *Supplemental.* Using ridge regression and cross-validation in scikit-learn. N/A 18.8 *Supplemental.* Using LASSO regression and cross-validation in scikit-learn. N/A 18.9 *Supplemental.* An overview of the bias-variance tradeoff, and how it interfaces with regularization. N/A",
    "url": "http://localhost:4000/sp22/lecture/lec18/",
    "relUrl": "/lecture/lec18/"
  },
  "26": {
    "id": "26",
    "title": "Lecture 19 – Physical Data and the Climate",
    "content": "Lecture 19 – Physical Data and the Climate Presented by Dr. Chelle Gentemann Content by Dr. Chelle Gentemann slides code playlist Video Quick Check 19 Guest lecture on climate data with oceanographer Dr. Chelle Gentemann.",
    "url": "http://localhost:4000/sp22/lecture/lec19/",
    "relUrl": "/lecture/lec19/"
  },
  "27": {
    "id": "27",
    "title": "Lecture 20 – Gradient Descent",
    "content": "Lecture 20 – Gradient Descent Presented by Anthony D. Joseph Content by Josh Hug, Joseph Gonzalez slides video playlist code Loss Game A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 20.1 Gradient descent in one dimension. Convexity. 20.1 20.2 Various methods of optimizing loss functions in one dimension. 20.2 20.3 Gradient descent in multiple dimensions. Interpretation of gradients. 20.3 20.4 Stochastic gradient descent (SGD). Comparison between gradient descent and SGD. 20.4",
    "url": "http://localhost:4000/sp22/lecture/lec20/",
    "relUrl": "/lecture/lec20/"
  },
  "28": {
    "id": "28",
    "title": "Lecture 21 – Principal Components Analysis",
    "content": "Lecture 21 – Principal Components Analysis Presented by Anthony D. Joseph Content by Josh Hug, John DeNero, Sam Lau, and Suraj Rampure slides video playlist code Summer 2020 PCA notes PCA tutorial A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 22.1 Dimensionality. Visualizing high-dimensional data. 22.1 22.2 More visualizations of high-dimensional data. 22.2 22.3 Matrix decomposition, redundancy, and rank. Introduction to the singular value decomposition (SVD). 22.3 22.4 The theory behind the singular value decomposition. Orthogonality and orthonormality. 22.4 22.5 Definition and computation of principal components. Geometric interpretation of principal components and low rank approximations. Data centering. 22.5 22.6 Interpretation of singular values. The relationship between singular values and variance. Analyzing scree plots. 22.6 22.7 Introduction to principal Component analysis (PCA). PCA for exploratory data analysis. 22.7",
    "url": "http://localhost:4000/sp22/lecture/lec21/",
    "relUrl": "/lecture/lec21/"
  },
  "29": {
    "id": "29",
    "title": "Lecture 22 – Logistic Regression, Part 1",
    "content": "Lecture 22 – Logistic Regression, Part 1 Presented by Presented by Fernando Perez, Suraj Rampure Content by Suraj Rampure, Josh Hug, Joseph Gonzalez, Ani Adhikari slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 22.0 Logistics 22.1 Classification, and a brief overview of the machine learning taxonomy. 22.1 22.2 Pitfalls of using least squares to model probabilities. Creating a graph of averages to motivate the logistic regression model. 22.2 22.3 Deriving the logistic regression model from the assumption that the log-odds of the probability of belonging to class 1 is linear. 22.3 22.4 Formalizing the logistic regression model. Exploring properties of the logistic function. Interpreting the model coefficients. 22.4 22.5 Discussing the pitfalls of using squared loss with logistic regression. 22.5 22.6 Introducing cross-entropy loss, as a better alternative to squared loss for logistic regression. 22.6 22.7 Using maximum likelihood estimation to arrive at cross-entropy loss. 22.7 22.8 Demo of using scikit-learn to fit a logistic regression model. An overview of what&#39;s coming next. 22.8",
    "url": "http://localhost:4000/sp22/lecture/lec22/",
    "relUrl": "/lecture/lec22/"
  },
  "30": {
    "id": "30",
    "title": "Lecture 23 – Logistic Regression Part II, Classification",
    "content": "Lecture 23 – Logistic Regression Part II, Classification Presented by Fernando Perez Content by Suraj Rampure, Fernando Perez, Josh Hug, Joseph Gonzalez, Ani Adhikari slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 23.1 Using thresholds to convert from predicted probabilities to classifications. 23.1 23.2 Defining several metrics of classifier performance – accuracy, precision, and recall. Confusion matrices. 23.2 23.3 Using scikit-learn to compute accuracy, precision, recall, and confusion matrices. 23.3 23.4 Exploring how threshold impacts accuracy, precision, and recall. Precision-recall curves. ROC curves. AUC. 23.4 23.5 Exploring the decision boundaries that result from a logistic regression classifier, and their relationship to the model&#39;s parameters. 23.5 23.6 Linear separability. Why we sometimes need regularization for logistic regression. 23.6 23.7 Summary. Brief introduction to multiclass classification.",
    "url": "http://localhost:4000/sp22/lecture/lec23/",
    "relUrl": "/lecture/lec23/"
  },
  "31": {
    "id": "31",
    "title": "Lecture 24 – Decision Trees",
    "content": "Lecture 24 – Decision Trees Presented by Anthony D. Joseph Content by Josh Hug slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 24.1 Decision tree basics. Decision trees in scikit-learn. 24.1 24.2 Overfitting and decision trees. 24.2 24.3 Decision tree generation. Finding the best split. Entropy and weighted entropy. 24.3 24.4 Restricting decision tree complexity. Preventing growth and pruning. Random forests and bagging. 24.4 24.5 Regression trees. Summary of decision trees, classification, and regression. 24.5",
    "url": "http://localhost:4000/sp22/lecture/lec24/",
    "relUrl": "/lecture/lec24/"
  },
  "32": {
    "id": "32",
    "title": "Lecture 25 – Inference for Modeling",
    "content": "Lecture 25 – Inference for Modeling Presented by Fernando Perez and Suraj Rampure Content by Suraj Rampure, Fernando Perez, John DeNero, Sam Lau, Ani Adhikari, Deb Nolan slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 25.1 A big picture overview of inference. Parameters and estimators. Bias and variance of estimators. The sample mean estimator. 25.1 25.2 Using bootstrap resampling in order to estimate the sampling distribution of an estimator. 25.2 25.3 Defining confidence intervals more generally. Describing and demoing how we can use the bootstrap to create confidence intervals for population parameters. 25.3 25.4 The assumptions we make when modeling with linear regression.. 25.4 25.5 Using the bootstrap to estimate the sampling distributions of parameters in a linear regression model. Inference for the true slope of a feature. 25.5 25.6 Multicollinearity, and its impacts on the interpretability of the parameters of our model. A summary of the lecture, and a brief overview of the ML taxonomy. 25.6",
    "url": "http://localhost:4000/sp22/lecture/lec25/",
    "relUrl": "/lecture/lec25/"
  },
  "33": {
    "id": "33",
    "title": "Lecture 26 – Clustering",
    "content": "Lecture 26 - Clustering Presented by Anthony D. Joseph Content by Josh Hug slides video playlist code A reminder – the right column of the table below contains Quick Checks. These are not required but suggested to help you check your understanding. Video Quick Check 26.1 Introduction to clustering. Examples of clustering in practice. 26.1 26.2 The K-Means clustering algorithm. Example of K-Means clustering. 26.2 26.3 Loss functions for K-Means. Inertia and distortion. Optimizing inertia. 26.3 26.4 Agglomerative clustering as an alternative to K-Means. Example of agglomerative clustering. Dendrograms and other clustering algorithms. 26.4 26.5 Picking the number of clusters. The elbow method and silhouette scores. Summary of clustering and machine learning. 26.5",
    "url": "http://localhost:4000/sp22/lecture/lec26/",
    "relUrl": "/lecture/lec26/"
  },
  "34": {
    "id": "34",
    "title": "Lecture 27 – Social Cost of Carbon",
    "content": "Lecture 27 - Social Cost of Carbon Presented by David Anthoff Content by David Anthoff video playlist slides pt 1 slides pt 2 Video 27.1 Part 1 27.2 Part 2 27.3 Part 3",
    "url": "http://localhost:4000/sp22/lecture/lec27/",
    "relUrl": "/lecture/lec27/"
  },
  "35": {
    "id": "35",
    "title": "Resources",
    "content": "Resources Here is a collection of resources that will help you learn more about various concepts and skills covered in the class. Learning by reading is a key part of being a well rounded data scientist. We will not assign mandatory reading but instead encourage you to look at these and other materials. If you find something helpful, post it on EdStem, and consider contributing it to the course website. Jump to: Optional Supplementary Textbook Exam Resources Course Website Local Setup Coding and Probability Resources Pandas SQL Resources Probability Practice Regex Practice LaTeX Tips Other Web References Books Data Science Education Optional Supplementary Textbook Alongside each lecture are optional textbook readings to the Data 100 textbook, Principles and Techniques of Data Science. Textbook readings are purely supplementary, and may contain material that is not in scope (and may also not be comprehensive). The textbook is actively in development during Spring 2022! Some readings may become out-of-date or reordered as the semester progresses. If you see a reading on our schedule that no longer exists, don’t hesitate to send a pull request to our course GitHub (see below). Exam Resources Semester Midterm (1) Midterm 2 Final Fall 2021 Exam (Solutions)     Summer 2021 Exam (Solutions) [Video]   Exam (Solutions) Spring 2021 Exam (Solutions)   Exam (Solutions) Fall 2020 Exam (Solutions)   Exam (Solutions) Summer 2020 Exam (Solutions) Exam (Solutions) Exam (Solutions) Spring 2020 Checkpoint (Solutions)   N/A Fall 2019 Exam (Solutions) Exam (Solutions) Exam (Solutions) Summer 2019 Exam (Solutions) [Video]   Exam (Solutions) Spring 2019 Exam (Solutions) [Video] Exam (Solutions) [Video] Exam (Solutions) Fall 2018 Exam (Solutions)   Exam (Solutions) Spring 2018 Exam (Solutions)   Exam (Solutions) [Video] Fall 2017 Exam (Solutions) [Video]   Exam (Solutions) Spring 2017 Exam (Solutions)   Exam (Solutions) Spring 2020 Checkpoint Reference Sheet Fall 2019 Midterm 1 Reference Sheet Spring 2019 Midterm 1 Reference Sheet Course Website We will be posting all lecture materials on the course syllabus. In addition, they will also be listed in the following publicly visible Github Repo. You can send us changes to the course website by forking and sending a pull request to the course website github repository. You will then become part of the history of Data 100 at Berkeley. Local Setup NOTE: This section is out of date and no longer supported by the course staff. Click here to read our guide on how to set up our development environment locally (as an alternative to using DataHub). Please note that any autograder tests will only work on DataHub. Coding and Probability Resources Pandas DS100 Textbook Pandas Reference Table Pandas API Reference The Pandas Cookbook: This provides a nice overview of some of the basic Pandas functions. However, it is slightly out of date. Learn Pandas A set of lessons providing an overview of the Pandas library. Python for Data Science Another set of notebook demonstrating Pandas functionality. SQL Resources We’ve assembled some SQL Review Slides to help you brush up on SQL. We’ve also compiled a list of SQL practice problems, which can be found here, along with their solutions. This SQL Cheat Sheet is an awesome resource that was created by Luke Harrison, a former Data 100 student. Probability Practice We’ve compiled a few practice probability problems that we believe may help in understanding the ideas covered in the course. They can be found here, along with their solutions. We’d also like to point you to the textbook for Stat 88, an introductory probability course geared towards data science students at Berkeley. Regex Practice We’ve organized some regular expressions(regex) problems to help you get extra practice on regex in a notebook format. They can be found here, along with their solutions. The official Python3 regex guide is good: link DS100 Reference Sheet LaTeX Tips Quick Guide to LaTeX Check out these handy LaTeX tips For more about basic LaTeX formatting, you can read this article. Other Web References As a data scientist you will often need to search for information on various libraries and tools. In this class we will be using several key python libraries. Here are their documentation pages: The Bash Command Line: Linux and Bash: Intro to Linux, Cloud Computing (which you can skip for the purposes of this class), and the Bash command line. You can skip all portions that don’t pertain to using the command line. Bash Part 2: Part 2 of the intro to command line. Python: DS100 Textbook scikit-learn Reference Table Python Tutorial: Teach yourself python. This is a pretty comprehensive tutorial. Python + Numpy Tutorial this tutorial provides a great overview of a lot of the functionality we will be using in DS100. Python 101: A notebook demonstrating a lot of python functionality with some (minimal explanation). Data Visualization: DS100 Textbook Seaborn Reference Table and Matplotlib Reference Table matplotlib.pyplot tutorial: This short tutorial provides an overview of the basic plotting utilities we will be using. Altair Documentation: Altair(Vega-Lite) is a new and powerful visualization library. We might not get to teach it this semester, but you should check it out if you are interested in pursuing visualization deeper. In particular, you should find the example gallery helpful. Prof. Jeff Heer’s Visualization Curriculum: This repository contains a series of Python-based Jupyter notebooks that teaches data visualization using Vega-Lite and Altair. If you are interested in learning more about data visualization, you can find more materials in: Edward Tufte’s book sequences – a classic! Prof. Heer’s class. Books Because data science is a relatively new and rapidly evolving discipline there is no single ideal textbook for this subject. Instead we plan to use reading from a collection of books all of which are free. However, we have listed a few optional books that will provide additional context for those who are interested. Principles and Techniques of Data Science, the Data 100 textbook. Introduction to Statistical Learning (Free online PDF) This book is a great reference for the machine learning and some of the statistics material in the class Data Science from Scratch (Available as eBook for Berkeley students) This more applied book covers many of the topics in this class using Python but doesn’t go into sufficient depth for some of the more mathematical material. Doing Data Science (Available as eBook for Berkeley students) This books provides a unique case-study view of data science but uses R and not Python. Python for Data Analysis (Available as eBook for Berkeley students). This book provides a good reference for the Pandas library. Data Science Education Interested in bringing the Data Science major or curriculum to your academic institution? Please fill out this form if you would like support from Berkeley in offering some variant of our Data Science courses at your institution (or just to let us know that you’re interested). Information about the courses appear at data8.org and ds100.org. Please note that this form is only for instructors. If you are only interested in learning Python or data science, please look at our Data 8 or Data 100 websites mentioned above.",
    "url": "http://localhost:4000/sp22/resources/",
    "relUrl": "/resources/"
  },
  "36": {
    "id": "36",
    "title": "Local Setup",
    "content": "Local Setup We will still be using datahub as our primary computing environment. This page serves as a guide for alternative environment setup. In other words: you don’t have to follow these instructions unless you’d like an alternative to datahub. Contents Installing conda by OS OSX Windows Linux Creating your environment Working on assignments locally Opening notebooks locally Verifying your environment Removing the environment to start over Submitting your work FAQ OSX You will need access to the command line. On a Mac, you can open the Terminal by opening Spotlight (Cmd + Space) and typing &quot;Terminal&quot;. Alternatively, you can go to your Applications screen and select Terminal (it might be in the folder named &quot;Other&quot;) Homebrew is a package manager for OSX. If you haven’t already, install it by running the following in the command line (copy, paste, and enter): # This downloads the Ruby code of the installation script and runs it /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Verify your installation by making sure brew --version doesn’t error at your terminal. Download and install Anaconda: # Uses curl to download the installation script curl https://repo.continuum.io/miniconda/Miniconda2-4.5.11-MacOSX-x86_64.sh &gt; miniconda.sh # Run the miniconda installer (you will need to enter your password) bash miniconda.sh Close and restart your terminal. Ensure the installation worked by running conda --version. You may remove the miniconda.sh script now if you’d like. Click here to continue to the next part of the setup. Windows Windows is especially prone to error if you aren’t careful about your configuration. If you’ve already had Anaconda or git installed and can’t get the other to work, try uninstalling everything and starting from scratch. Installing Anaconda: Visit the Anaconda website and download the installer for Python 3.7. Download the 64-bit installer if your computer is 64-bit (most likely), the 32-bit installer if not. See this FAQ if you are unsure. Run the exe file to install Anaconda. Leave all the options as default (install for all users, in the default location). Make sure both of these checkboxes are checked: 1) Verify that the installation is working by starting the Anaconda Prompt (you should be able to start it from the Start Menu) and typing python: Notice how the python prompt shows that it is running from Anaconda. Now you have conda installed! From now on, when we talk about the “Terminal” or “Command Prompt”, we are referring to the Anaconda Prompt that you just installed. Click here to continue to the next part of the setup. Linux These instructions assume you have apt-get (Ubuntu and Debian). For other distributions of Linux, substitute the appropriate package manager. Your terminal program allows you to type commands to control your computer. On Linux, you can open the Terminal by going to the Applications menu and clicking “Terminal”. Install wget. This is a command-line tool that lets you download files / webpages at the command line. sudo apt-get install wget Download the Anaconda installation script: wget -O install_anaconda.sh https://repo.continuum.io/miniconda/Miniconda2-4.5.11-Linux-x86_64.sh 4) Install Anaconda: bash install_anaconda.sh 5) Close and restart your terminal. Ensure the installation worked by running `conda --version`. You may remove the install_anaconda.sh script now if you’d like. Click here to continue to the next part of the setup. Creating your environment These instructions are the same for OSX, Windows, and Linux. Download the data100 data100_environment.yml] from the course repository here or: # download via curl curl https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml &gt; data100_environment.yml # OR download via wget wget -O data100_environment.yml https://raw.githubusercontent.com/DS-100/su20/gh-pages/resources/assets/local_setup/data100_environment.yml This YAML file is what we use to specify the dependencies and packages (and their versions) we wish to install into the conda environment we will make for this class. The purpose of the environment is to ensure that everyone in the course is using the same package versions for every assignment whether or not they are working on datahub. This is to prevent inconsistent behavior due to differences in package versions. Using the Terminal, navigate to the directory where you downloaded data100_environment.yml. Run these commands to create a new conda environment. Each conda environment maintains its own package versions, allowing us to switch between package versions easily. For example, this class uses Python 3, but you might have another that uses Python 2. With a conda environment, you can switch between those at will. # sanity check on conda installation. Should be 4.5 or higher conda --version # update conda just in case it&#39;s out of date # enter y if prompted to proceed conda update conda # download git conda install -c anaconda git # Create a python 3.6 conda environment with the full set # of packages specified in environment.yml (jupyter, numpy, pandas, ...) conda env create -f data100_environment.yml # Switch to the data100 environment conda activate data100 # Check if packages are in the environment # This should not be empty! conda list From now on, you can switch to the data100 env with conda activate data100, and switch back to the default env with conda deactivate. Working on assignments locally These instructions are the same for OSX, Windows, and Linux. To work on assignments, you should fetch the assignment on datahub, navigate to the assignment folder and click on the download icon on the top right: Then you can unzip the files into a folder of your choosing. Remember the location of your assignment files because you’ll need to navigate to that folder to open the notebook. Opening notebooks locally To open Jupyter notebooks, you’ll navigate to parent directory of the assignment in your terminal, activate the environment, and start up a jupyter server. This will look something like: cd path/to/assignment/directory conda activate data100 jupyter notebook This will automatically open the notebook interface in your browser. You can then browse to a notebook and open it. Make sure to always work in the data100 conda environment when you are using jupyter notebooks for this class. This ensures you have all the necessary packages required for the notebook to run. Verifying Your Environment You can tell if you are correct environment if your terminal looks something like: Additionally, conda env list outputs a list of all your conda environments, and data100 should appear with a * next to it (the active one). Removing the environment to start over If you feel as if you’ve messed up and need to start over, you can remove the environment with conda remove --name data100 --all To verify that the environment was removed, in your Terminal window or an Anaconda Prompt, run: conda info --envs Which should then no longer display the data100 environment. Submitting your work Submissions will still be handled via datahub. To upload your work, navigate to the appropriate assignment folder on datahub and click on the upload button on the top right. Remember to validate, submit, and upload to Gradescope (for homeworks and projects). FAQ Shell not properly configured to use conda activate If you had an older version of Anaconda installed (perhaps for another class), you may see the following message. Follow the instructions in the prompt to: Enable conda for all users sudo ln -s ... Put the base environment on PATH echo &quot;conda activate&quot; &gt;&gt; ~/.bash_profile&quot;. Note that ~/.bash_profile may be something different like ~/.bashrc. Manually remove the line that looks like export PATH=&quot;/usr/local/miniconda3/bin:$PATH&quot; from your .bash_profile. Use your favorite plaintext editor to do this (do not use a rich text editor like Microsoft Word!).",
    "url": "http://localhost:4000/sp22/setup/",
    "relUrl": "/setup/"
  },
  "37": {
    "id": "37",
    "title": "Staff",
    "content": "Staff Jump to Instructors, Teaching Assistants, or Tutors Note: Consult the calendar for the most up-to-date office hours for each GSI. Instructors {% assign instructors = site.staffers | where: &#39;role&#39;, &#39;Instructor&#39; %} {% for staffer in instructors %} {{ staffer }} {% endfor %} Teaching Assistants {% assign teaching_assistants = site.staffers | where: &#39;role&#39;, &#39;Teaching Assistant&#39; %} {% for staffer in teaching_assistants %} {{ staffer }} {% endfor %} Tutors {% assign readers = site.staffers | where: &#39;role&#39;, &#39;Tutor&#39; %} {% for staffer in readers %} {{ staffer }} {% endfor %}",
    "url": "http://localhost:4000/sp22/staff/",
    "relUrl": "/staff/"
  },
  "38": {
    "id": "38",
    "title": "Syllabus",
    "content": "Syllabus Jump to: About Data 100 Prerequisites Course Culture Be Aware of Your Actions Be Respectful Communicate Issues with Course Staff Course Components Lecture Discussion Homework and Projects Lab Office Hours and Communication Weekly Checks Exams Graduate Final Project Policies Grading Scheme Late Policy Regrade Requests Collaboration Policy and Academic Dishonesty We want you to succeed! Additional Resources About Data 100 Combining data, computation, and inferential thinking, data science is redefining how people and organizations solve challenging problems and understand their world. This intermediate level class bridges between Data 8 and upper division computer science and statistics courses as well as methods courses in other fields. In this class, we explore key areas of data science including question formulation, data collection and cleaning, visualization, statistical inference, predictive modeling, and decision making.​ Through a strong emphasis on data centric computing, quantitative critical thinking, and exploratory data analysis, this class covers key principles and techniques of data science. These include languages for transforming, querying and analyzing data; algorithms for machine learning methods including regression, classification and clustering; principles behind creating informative data visualizations; statistical concepts of measurement error and prediction; and techniques for scalable data processing. Goals Prepare students for advanced Berkeley courses in data-management, machine learning, and statistics, by providing the necessary foundation and context. Enable students to start careers as data scientists by providing experience working with real-world data, tools, and techniques. Empower students to apply computational and inferential thinking to address real-world problems. Prerequisites While we are working to make this class widely accessible, we currently require the following (or equivalent) prerequisites. Unlike past semesters, prerequisites will be enforced in this class. It is your responsibility to know the material in the prerequisites. The instructors do not have the authority to waive these requirements. You should contact CDSS at https://data.berkeley.edu/academics/data-science-undergraduate-studies/courses/spring-2022-classes to request an exception. Foundations of Data Science: Data 8 covers much of the material in Data 100 but at an introductory level. Data8 provides basic exposure to python programming and working with tabular data as well as visualization, statistics, and machine learning. Computing: The Structure and Interpretation of Computer Programs (CS 61A) or Computational Structures in Data Science (CS 88). These courses provide additional background in python programming (e.g., for loops, lambdas, debugging, and complexity) that will enable Data 100 to focus more on the concepts in Data Science and less on the details of programming in python. Math: Linear Algebra (Math 54, EE 16A, or Stat 89A): We will need some basic concepts like linear operators, eigenvectors, derivatives, and integrals to enable statistical inference and derive new prediction algorithms. This may be satisfied concurrently to Data 100. Course Culture Students taking Data C100/C200 come from a wide range of backgrounds. We hope to foster an inclusive and safe learning environment based on curiosity rather than competition. All members of the course community—the instructor, students, and GSIs—are expected to treat each other with courtesy and respect. Some of the responsibility for that lies with the staff, but a lot of it ultimately rests with you, the students. Be Aware of Your Actions Sometimes, the little things add up to creating an unwelcoming culture to some students. For example, you and a friend may think you are sharing in a private joke about other races, majors, genders, abilities, cultures, etc. but this can have adverse effects on classmates who overhear it. There is a great deal of research on something called “stereotype threat,” which finds simply reminding someone that they belong to a particular culture or share a particular identity (on whatever dimension) can interfere with their course performance. Stereotype threat works both ways: you can assume that a student will struggle based on who they appear to be, or you can assume that a student is doing great based on who they appear to be. Both are potentially harmful. Bear in mind that diversity has many facets, some of which are not visible. Your classmates may have medical conditions (physical or mental), personal situations (financial, family, etc.), or interests that aren’t common to most students in the course. Another aspect of professionalism is avoiding comments that (likely unintentionally) put down colleagues for situations they cannot control. Bragging in open space that an assignment is easy or “crazy,” for example, can send subtle cues that discourage classmates who are dealing with issues that you can’t see. Please take care, so we can create a class in which all students feel supported and respected. Be Respectful Beyond the slips that many of us make unintentionally are a host of behaviors that the course staff, department, and university do not tolerate. These are generally classified under the term harassment; sexual harassment is a specific form that is governed by federal laws known as Title IX. UC Berkeley’s Title IX website provides many resources for understanding the terms, procedures, and policies around harassment. Make sure you are aware enough of these issues to avoid crossing a line in your interactions with other students. For example, repeatedly asking another student out on a date after they have said no can cross this line. Your reaction to this topic might be to laugh it off, or to make or think snide remarks about “political correctness” or jokes about consent or other things. You might think people just need to grow a thicker skin or learn to take a joke. This isn’t your decision to make. Research shows the consequences (emotional as well as physical) on people who experience harassment. When your behavior forces another student to focus on something other than their education, you have crossed a line. You have no right to take someone else’s education away from them. Communicate Issues with Course Staff Professionalism and respect for diversity are not just matters between students; they also apply to how the course staff treat the students. The staff of this course will treat you in a way that respects our differences. However, despite our best efforts, we might slip up, hopefully inadvertently. If you are concerned about classroom environment issues created by the staff or overall class dynamic, please feel free to talk to us about it. The instructors and the Head TA ({{page.course.head_ta}}) in particular welcome any comments or concerns regarding conduct of the course and the staff. We are committed to creating a learning environment welcoming of all students that supports a diversity of thoughts, perspectives and experiences and respects your identities and backgrounds (including race, ethnicity, nationality, gender identity, socioeconomic class, sexual orientation, language, religion, ability, and more.) To help accomplish this: If your name and/or pronouns differ from those that appear in your official records, please let us know. If you feel like your performance in the class is being affected by your experiences outside of class (e.g., family matters, current events), please don’t hesitate to come and talk with us. We want to be resources for you. We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. While the course staff understands that improving diversity, equity, and inclusion (DEI) are not enough to overcome systemic issues in academia such as racism, queerphobia, and other forms of discrimination and hatred, we also recognize the importance of DEI work. The Data Science Department has some resources available at https://data.berkeley.edu/about/diversity-equity-and-inclusion. There’s also a great set of resources available at https://eecs.berkeley.edu/resources/students/grievances. If there are other resources you think we should list here, let us know! We take all complaints about unprofessional or discriminatory behavior seriously. Course Components Below is a high-level “typical week in the course” for Spring 2022. Mo Tu We Th Fr   Office Hours Office Hours Office Hours     Live Lecture   Live Lecture           Discussion Section       Homework N due Homework N+1 released   Lab N HelpLab N due     Lab N+1 released Weekly check due/released         All deadlines are subject to change. Note: In-person meetings are fully dependent on public health guidelines. We are prepared to hold all course activities online should circumstances demand. If you have COVID symptoms, please do not attend in-person activities. Instead, please keep up with the class using the online or asynchronous modes of participation (Zoom, EdStem). Office Hours are scheduled on the Calendar page. Lectures, discussions, assignments, projects, and exams are scheduled on the Home page. Lecture There are 2 live lectures per week. You can attend hybrid all semester: in-person or via Zoom as permitted by campus policy. All lecture recordings will also be published within 24 hours of the live recording. Discussion Live discussion sections are on Fridays, lasting for one hour. The goal of these sessions is to work through problems, hone your skills, and flesh out your understanding as part of a team. The problems that you solve and present as part of discussion are important in understanding this material. You must be assigned to a discussion section, even if you don’t intend on regularly attending. To encourage attendance and participation in live discussion, you have the option to have discussion attendance contribute to your overall course grade. See Policies below for more details. Discussion sign-ups will be released the first week of class through Signup Genius: Ed post. Attendance points will only be given for the section you are assigned to. You can switch sections via the sign-up form through the end of the 3rd week, Friday 2/24/2022. From the 4th week onwards, your section will be locked in for the rest of the semester. Due to room restrictions, you may not attend an in-person section that you were not assigned to; there is no such restriction on online sections. However, you must still attend the section you are assigned to. In a typical week, we will release the discussion worksheet on Friday morning and solutions on Saturday. We are still receiving guidance as to whether we can provide physical handouts during in-person discussions. Homework and Projects Homeworks are week-long assignments that are designed to help students develop an in-depth understanding of both the theoretical and practical aspects of ideas presented in lecture. Projects: Projects are two-week long assignments that synthesize multiple topics. In a typical week, the homework (or project) is released Friday through DataHub and is due the following Thursday at 11:59PM Pacific through Gradescope (updated 1/26). One or two homeworks will be on-paper written assignments; the rest will be Jupyter notebooks. See the Policies section for grading details. Homeworks and projects have both visible and hidden autograder tests. The visible tests are mainly sanity checks. For example, a sanity check might verify that the answer you entered is a number as expected, and not a word. The hidden tests generally check for correctness, and are invisible to students while they are doing the assignment. The primary form of support students will have for homeworks and projects are the office hours we’ll host, and Ed. Homeworks and projects must be completed individually. See the Collaboration Policy for more details. Lab Labs are shorter programming assignments designed to give students familiarity with new ideas. In a typical week, the lab is released on Friday through DataHub and is due the following Tuesday at 11:59PM through Gradescope (updated 1/26). All lab autograder tests are visible. In lieu of official lab sections, we will be helping with lab in several ways: Lab walkthroughs, which are recorded videos posted as part of the lab. Lab Help Sections, which are Tuesday office hours that prioritize lab debugging and questions. See the Calendar and our Office Hours for more details. EdStem. All labs are intended to take about an hour. You can therefore think of Lab Help Sections as lab sections, where attendance is not required nor expected to complete the lab. The best place to get individual help with lab is Lab Help Sections. Office Hours and Communication The office hours and locations are listed on the Calendar; office hours will be held both virtually and in-person. Instructor office hours are also listed on the calendar. To adhere to public health guidelines, we ask that students leave the OH room after their questions have been answered. In general, students can come to office hours for any questions on course assignments or material. Note that events labeled Lab Help Sections will prioritize lab debugging and questions, after which other questions can be addressed. Virtual OH can be accessed via oh.ds100.org, where students add themselves to the “queue” and specify the assignment they need help on. EdStem, or Ed for short, is our course forum this quarter. The course is here. Please check out EdStem or the FAQ page first before emailing instructors. Staff email: You can email {{page.course.email}} and one of the instructors will get back to you. Note that to ensure more timely responses, this address is monitored by the team of the two lead instructors (Josh Hug and Lisa Yan) the Head TA ({{page.course.head_ta}}), as well as several lead GSIs, to ensure more timely responses. You can contact Josh and Lisa directly for matters that require strict privacy and their direct attention. Weekly Checks While lecture and discussion section attendance is not required, nor even expected, we do expect you to stay up to date with material. To help us keep track of your progress and sentiment about the course, there will be 14 weekly surveys due on Mondays at 11:59 PM Pacific. Weekly check-ins are submitted via Google Form, and links will be provided on the Home page each week. Weekly Checks are graded on completion, not correctness. Exams There will be three exams in this course: Midterm 1 on Thursday, February 24 (7-9PM Pacific) Midterm 2 on Thursday, April 7 (7-8:30PM Pacific). Note the shorter exam time period. Final exam during our scheduled slot, Friday, May 13, 7-10pm Pacific. We are still deciding proctoring format, but we will primarily have in-person exams with the option for virtual exams. Alternate exam times will be provided for all exams for pre-approved reasons, such as a concurrent final exam. If you miss an exam due to a personal emergency or illness, please email the Head TA {{page.course.head_ta}} at {{page.course.head_email}} immediately. In the first few weeks of the semester, we will be releasing forms for exam options on EdStem so that you can let us know of your conflicts (for both midterms and the final). DSP students will be offered the option for on-campus exams as per their accommodations. Graduate Final Project All students enrolled in the graduate version of the course (CS C200 or Stat C200C, i.e. Data 200) will be graded according to the Graduate grading scheme, which includes a graduate final project. More details to follow. Policies Grading Scheme Category Data C100 Data C200 Details Homeworks 22.5% 20% Drop lowest 2 scores Labs 10% 5% (or 0%, lab opt-out) Drop lowest 3 scores Projects 15% 10% (or 15%, lab opt-out)   Midterms 25% 25% Midterm 1: 15%Midterm 2: 10% Final 25% 25%   Weekly Check 2.5% - Drop lowest 4 scores Final Graduate Project - 15%   Optional attendance grading: For both graduate and undergraduates, you may substitute part of your Homework grade with Discussion attendance throughout the semester: Discussion attendance and homework will be 5% and 17.5%, respectively, of the overall grade. When calculating your overall grade at the end of the semester, we will automatically determine your homework grade as the maximum of your homework grade with and without attendance. Attending 11 of the 14 scheduled discussions is considered full attendance credit (i.e., there are 3 drops). Grad lab opt-out: When calculating your overall grade at the end of the semester, we will automatically take the max of your grade with and without labs. Late Policy All assignments are due at 11:59 pm Pacific on the due date specified on the syllabus. Homeworks, labs, and weekly checks will not be accepted late. Google Forms (weekly checks) will promptly close after the deadline. Gradescope (labs and homeworks) may allow you to make late submissions, but you will later be given a 0. Projects are marked down by 10% per day, up to two days. After two days, project submissions will not be accepted. Submission times are rounded up to the next day. That is, 2 minutes late = 1 day late. Extensions are only provided to students with DSP accommodations, or in the case of exceptional circumstances. If you have DSP accommodations, you should expect to receive an email from us. Otherwise, email our Communications TA {{page.course.comms_ta}} at {{page.course.comms_email}} to request an extension. If you make a request close to the deadline, we can not guarantee that you will receive a response before the deadline. Additionally, simply submitting a request does not guarantee you will receive an extension. Even if your work is incomplete, please submit before the deadline so you can receive credit for the work you did complete. Note that extension requests will not be granted in cases where a student’s local (DataHub) tests are not passing. It is the student’s responsibility to solve such problems in advance of the deadline. Regrade Requests Students will be allowed to submit regrade requests for the autograded and written portions of assignments in cases in which the rubric was incorrectly applied or the autograder scored their submission incorrectly. Regrades for the written portions of assignments will be handled through Gradescope, and autograder regrades via a Google Form here. The deadline for regrade requests (autograded and written) is one week after grades are released for the corresponding assignment. Always check that the autograder executes correctly! Gradescope will show you the output of the public tests, and you should see the same results as you did on DataHub. If you see a discrepancy, ensure that you have exported the assignment correctly and, if there is still an issue, post on EdStem as soon as possible. Regrade requests will not be considered in cases in which: a student uploads the incorrect file to the autograder. the autograder fails to execute and the student does not notify the course staff before the assignment deadline. a student fails to save their notebook before exporting and uploads an old version to the autograder. a situation arises in which the course staff cannot ensure that the student’s work was done before the assignment deadline. Collaboration Policy and Academic Dishonesty We will be following the EECS departmental policy on Academic Honesty, which states that using work or resources that are not your own or not permitted by the course may lead to disciplinary actions, up to and including a failing grade in the course. Assignments. Data science is a collaborative activity. While you may talk with others about the homework and projects, we ask that you write your solutions individually in your own words. If you do discuss the assignments with others please include their names at the top of your notebook. Keep in mind that content from assignments will likely be covered on both the midterm and final. If we suspect that you have submitted plagiarized work, we will call you in for a meeting. If we then determine that plagiarism has occurred, we reserve the right to give you a negative full score (-100%) or lower on the assignments in question, along with reporting your offense to the Center of Student Conduct. Rather than copying someone else’s work, ask for help. You are not alone in this course! The entire staff is here to help you succeed. If you invest the time to learn the material and complete the assignments, you won’t need to copy any answers. (taken from CS61A) We also ask that you do not post your assignment solutions publicly. Exams. Cheating on exams is a serious offense. We have methods of detecting cheating on exams – so don’t do it! Students caught cheating on any exam will fail this course. We want you to succeed! If you are feeling overwhelmed, visit our office hours and talk with us. We know college can be stressful – and especially so during the COVID-19 pandemic – and we want to help you succeed. Important Note: We are committed to being a resource to you, but it is important to note that all members of the teaching staff for this course are responsible employees, meaning that we must disclose any incidents of sexual harassment or violence to campus authorities. If you would like to speak to a confidential advocate, please consider reaching out to the Berkeley PATH to Care Center. Additional Resources Please see our Resources page for course content resources, including the optional supplementary textbook. COVID-19 Resources and Support You can find UC Berkeley’ COVID-19 resources and support here. For academic performance, support, and technology The Center for Access to Engineering Excellence (Bechtel Engineering Center 227) is an inclusive center that offers study spaces, nutritious snacks, and tutoring in &gt;50 courses for Berkeley engineers and other majors across campus. The Center also offers a wide range of professional development, leadership, and wellness programs, and loans iclickers, laptops, and professional attire for interviews. As the primary academic support service for undergraduates at UC Berkeley, the Student Learning Center (510-642-7332) assists students in transitioning to Cal, navigating the academic terrain, creating networks of resources, and achieving academic, personal, and professional goals. Through various services including tutoring, study groups, workshops, and courses, SLC supports undergraduate students in Biological and Physical Sciences, Business Administration, Computer Science, Economics, Mathematics, Social Sciences, Statistics, Study Strategies, and Writing. The Educational Opportunity Program (EOP, Cesar Chavez Student Center 119; 510-642-7224) at Cal has provided first generation and low income college students with the guidance and resources necessary to succeed at the best public university in the world. EOP’s individualized academic counseling, support services, and extensive campus referral network help students develop the unique gifts and talents they each bring to the university while empowering them to achieve. The Student Technology Equity Program connects laptops, Wi-Fi hotspots, and other required technology to students in need. For mental well-being The staff of the UHS Counseling and Psychological Services (Tang Center, 2222 Bancroft Way; 510-642-9494; for after-hours support, please call the 24/7 line at 855-817-5667) provides confidential, brief counseling and crisis intervention to students with personal, academic and career stress. Services are provided by a multicultural group of professional counselors including psychologists, social workers, and advanced level trainees. All undergraduate and graduate students are eligible for CAPS services, regardless of insurance coverage. To improve access for engineering students, a licensed psychologist from the Tang Center also holds walk-in appointments for confidential counseling in Bechtel Engineering Center 241 (check here for schedule). For disability accommodations The Disabled Students’ Program (DSP, 260 César Chávez Student Center #4250; 510-642-0518) serves students with disabilities of all kinds, including mobility impairments, blind or low vision, deaf or hard of hearing; chronic illnesses (chronic pain, repetitive strain injuries, brain injuries, AIDS/HIV, cancer, etc.) psychological disabilities (bipolar disorder, severe anxiety or depression, etc.), Attention Deficit Disorder/Attention Deficit Hyperactivity Disorder, and Learning Disabilities. Services are individually designed and based on the specific needs of each student as identified by DSP’s Specialists. The Program’s official website includes information on DSP staff, UCB’s disabilities policy, application procedures, campus access guides for most university buildings, and portals for students and faculty. For solving a dispute The Ombudsperson for Students (Sproul Hall 102; 510-642-5754) provides a confidential service for students involved in a University-related problem (academic or administrative), acting as a neutral complaint resolver and not as an advocate for any of the parties involved in a dispute. The Ombudsperson can provide information on policies and procedures affecting students, facilitate students’ contact with services able to assist in resolving the problem, and assist students in complaints concerning improper application of University policies or procedures. All matters referred to this office are held in strict confidence. The only exceptions, at the sole discretion of the Ombudsperson, are cases where there appears to be imminent threat of serious harm. The Student Advocate’s Office (SAO) is an executive, non-partisan office of the ASUC. We offer free, confidential casework services and resources to any student(s) navigating issues with the University, including academic, conduct, financial aid, and grievance concerns. All support is centered around students and aims for an equity-based approach. For recovery from sexual harassment or sexual assault The Care Line (510-643-2005) is a 24/7, confidential, free, campus-based resource for urgent support around sexual assault, sexual harassment, interpersonal violence, stalking, and invasion of sexual privacy. The Care Line will connect you with a confidential advocate for trauma-informed crisis support including time-sensitive information, securing urgent safety resources, and accompaniment to medical care or reporting. For social services Social Services provides confidential services and counseling to help students with managing problems that can emerge from illness such as financial, academic, legal, family concerns, and more. They specialize in helping students with pregnancy resources and referrals; alcohol/drug problems related to one’s own or a family member’s use; sexual assault/rape; relationship or other violence; and support for health concerns-new diagnoses or ongoing conditions. Social Services staff will assess a student’s immediate needs, work with the student to develop a plan to meet those needs, and facilitate arrangements with academic departments and advocate for the student with other campus offices and community agencies, as well as coordinate services within UHS. For finding community on campus The mission of the Berkeley International Office (2299 Piedmont Avenue, 510-642-2818) is to provide support with all the essential resources needed to not only survive, but thrive here at UC Berkeley. Their mission is to support you and work together towards justice and belonging for all. They define Basic Needs as the essential resources that impact your health, belonging, persistence, and overall well being. It is an ecosystem that includes: nutritious food, stable housing, hygiene, transportation, healthcare, mental wellness, financial sustainability, sleep, and emergency dependent services. They refuse to accept hunger, homelessness, and all other basic needs injustices as part of our university. The Gender Equity Resource Center, fondly referred to as GenEq, is a UC Berkeley campus community center committed to fostering an inclusive Cal experience for all. GenEq is the campus location where students, faculty, staff and Alumni connect for resources, services, education and leadership programs related to gender and sexuality. The programs and services of the Gender Equity Resource Center are focused into four key areas: women; lesbian, gay, bisexual, and transgender (LGBT); sexual and dating violence; and hate crimes and bias driven incidents. GenEq strives to provide a space for respectful dialogue about sexuality and gender; illuminate the interrelationship of sexism, homophobia and gender bias and violence; create a campus free of violence and hate; provide leadership opportunities; advocate on behalf of survivors of sexual, hate, dating and gender violence; foster a community of women and LGBT leaders; and be a portal to campus and community resources on LGBT, Women, and the many intersections of identity (e.g., race, class, ability, etc.). The Undocumented Students Program (119 Cesar Chavez Center; 642-7224) practices a holistic, multicultural and solution-focused approach that delivers individualized service for each student. The academic counseling, legal support, financial aid resources and extensive campus referral network provided by USP helps students develop the unique gifts and talents they each bring to the university, while empowering a sense of belonging. The program’s mission is to support the advancement of undocumented students within higher education and promote pathways for engaged scholarship. The Multicultural Education Program (MEP) is one of six initiatives funded by the Evelyn and Walter Haas, Jr. Fund to work towards institutional change and to create a positive campus climate for diversity. The MEP is a five-year initiative to establish a sustainable infrastructure for activities like educational consultation and diversity workshops for the campus that address both specific topics, and to cater to group needs across the campus. For basic needs (food, shelter, etc.) The Basic Needs Center (lower level of MLK Student Union, Suite 72) provides support with all the essential resources needed to not only survive, but thrive here at UC Berkeley. Their mission is to support you and work together towards justice and belonging for all. They define Basic Needs as the essential resources that impact your health, belonging, persistence, and overall well being. It is an ecosystem that includes: nutritious food, stable housing, hygiene, transportation, healthcare, mental wellness, financial sustainability, sleep, and emergency dependent services. They refuse to accept hunger, homelessness, and all other basic needs injustices as part of our university. The UC Berkeley Food Pantry (#68 Martin Luther King Student Union) aims to reduce food insecurity among students and staff at UC Berkeley, especially the lack of nutritious food. Students and staff can visit the pantry as many times as they need and take as much as they need while being mindful that it is a shared resource. The pantry operates on a self-assessed need basis; there are no eligibility requirements. The pantry is not for students and staff who need supplemental snacking food, but rather, core food support. Acknowledgments! Course Culture and Additional Resources inspired and adapted with permission from Dr. Sarah Chasins’ Fall 2021 CS 164 Syllabus and Grace O’Connell, the Asssociate Dean for Inclusive Excellence.",
    "url": "http://localhost:4000/sp22/syllabus/",
    "relUrl": "/syllabus/"
  }
  
}
